{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihoods we have used:\n",
    "1. regression: Gaussian\n",
    "2. count regression: \n",
    "    Poisson: lambda=e^f,  Poisson2: lambda=ln(1+e^f)\n",
    "3. binary classification: \n",
    "    Bernoulli: sigmoid,   Bernoulli2: Probit\n",
    "    \n",
    "For the sigmoid function, we use **expit** which is provided by *scipy.special*, because it is stable, fast and fairly accurate. Additionally, it is equivalent to sigmoid. For all methods, initial variational parameters are found by running the Laplace approximation on the subset/active set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv,norm,lstsq,cholesky\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.io as sio\n",
    "from sklearn import preprocessing\n",
    "import random,time,GPy\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import loggamma,roots_hermitenorm,gamma,expit\n",
    "from scipy.special import ndtr as std_norm_cdf\n",
    "\n",
    "_sqrt_2pi = np.sqrt(2*np.pi)\n",
    "_lim_val = np.finfo(np.float64).max\n",
    "_lim_val_exp = np.log(_lim_val)\n",
    "\n",
    "def std_norm_pdf(x): # define a standard normal pdf(from GPy)\n",
    "    x = np.clip(x,-1e300,1e300)\n",
    "    return np.exp(-np.square(x)/2)/_sqrt_2pi\n",
    "\n",
    "def safe_exp(f):\n",
    "    clip_f = np.clip(f, -np.inf, _lim_val_exp)\n",
    "    return np.exp(clip_f)\n",
    "\n",
    "def safe_ln(x, minval=0.0000000001):\n",
    "    return np.log(x.clip(min=minval))\n",
    "\n",
    "def kernel(X1, X2=None, l=1.0, sigma_f=1.0,K='SE'):\n",
    "    '''\n",
    "    Isotropic squared exponential kernel. Computes \n",
    "    a covariance matrix from points in X1 and X2.    \n",
    "    Args:\n",
    "        X1: Array of m points (m x d).\n",
    "        X2: Array of n points (n x d).\n",
    "\n",
    "    Returns:\n",
    "        Covariance matrix (m x n).\n",
    "    '''\n",
    "    if K=='diag': return sigma_f**2*np.ones((X1.shape[0], 1))\n",
    "    sqdist = np.sum(X1**2, 1).reshape(-1, 1) + np.sum(X2**2, 1) - 2 * np.dot(X1, X2.T);sqdist=np.absolute(sqdist)#.ravel()))\n",
    "    if K=='SE': return sigma_f**2 * np.exp(-0.5 / l**2 * sqdist);\n",
    "    elif K=='Matern32': return sigma_f**2 * (1+3**0.5*np.sqrt(sqdist)/l) * np.exp(-3**0.5*np.sqrt(sqdist)/l);\n",
    "    elif K=='Matern52': return sigma_f**2 * (1+3**0.5*np.sqrt(sqdist)/l+5*sqdist/(3*l**2)) * np.exp(-5**0.5*np.sqrt(sqdist)/l);\n",
    "\n",
    "def MFE(true_labels, pred_labels):\n",
    "    '''\n",
    "    Calculating mean fraction error(MFE) for count regression, the math is used as follows:\n",
    "    MFE = mean( abs( (true_labels - pred_labels)./true_labels ) ) \n",
    "    Written by Kaikai\n",
    "    '''    \n",
    "    if true_labels.size != pred_labels.size:\n",
    "        print('The size of true_labels and pred_labels is supposed to be identical.')\n",
    "        return -1    \n",
    "    true_labels = true_labels.flatten().astype('double'); pred_labels = pred_labels.flatten().astype('double')\n",
    "    true_labels_temp = true_labels.copy()\n",
    "    if 0 in true_labels: # replace zero with a very small positive value in order to avoid dividing by zero\n",
    "        print('There are elements of zero value in true labels.')\n",
    "        true_labels_temp[true_labels==0] = 1\n",
    "    \n",
    "    MFE = np.mean( np.abs( (true_labels - pred_labels)/true_labels_temp ) )\n",
    "    return MFE\n",
    "\n",
    "def calc_vlb(m,V, a, lik='Gaussian'):\n",
    "    prior_mean_u = a[0]; prior_mean_f = a[1] # prior mean for inducing points    \n",
    "    A = a[2] # Knm*inv(Kmm)\n",
    "    Kmm = a[3]; Kmm_inv = a[4]; Kmn = a[5]; Knn_diag = a[6]; y = a[7] # the ground truth for training data\n",
    "    noise_var = a[8]\n",
    "    num_train = len(prior_mean_f);num_inducing = len(prior_mean_u)\n",
    "    m_q = prior_mean_f + np.dot(A, (m-prior_mean_u)) # Eq.(3a) in paper\n",
    "    v_q = ( Knn_diag.ravel() + np.diag(np.dot(A, np.dot(V-Kmm, A.T))) )[:, None] # Eq.(3b) in paper\n",
    "#     v_q = np.absolute(v_q)\n",
    "    c1 = m - prior_mean_u; c2 = np.dot(Kmm_inv, c1);#print(v_q[:20],min(v_q))\n",
    "    (Sign,LogDetKmm) = np.linalg.slogdet(Kmm); LogDetKmm = Sign*LogDetKmm\n",
    "    (SignV,LogDetV) = np.linalg.slogdet(V); LogDetV = SignV*LogDetV;#print(v_q[:50])     \n",
    "    if lik=='Bernoulli':\n",
    "        f,w = GH_quad(m_q,np.sqrt(v_q));#vlb_lik = expit(y*f);print('yf',expit(y*f))\n",
    "        vlb_lik = np.sum( 1/_sqrt_2pi*np.dot( safe_ln(expit(y*f)) ,w) ) # sigmoid liklihood\n",
    "#         vlb_lik = np.sum( 1.0/np.sqrt(2*np.pi)*np.dot( np.log(std_norm_cdf(y*f)+1e-10) ,w) ) # Probit liklihood\n",
    "    elif lik=='Gaussian':\n",
    "        vlb_lik = -np.log(np.sqrt(2*np.pi*noise_var)) - np.sum((y-m_q)**2+v_q)/(2*noise_var)\n",
    "    elif lik=='Poisson':\n",
    "        vlb_lik = np.dot(y.T,m_q) - np.sum(loggamma(y+1)) - np.sum(np.exp(m_q+0.5*v_q))\n",
    "    elif lik=='Poisson2': # another link func: lambda=ln(1+e^f)\n",
    "        f,w = GH_quad(m_q,np.sqrt(v_q));\n",
    "        term1 = -np.sum(loggamma(y+1)); term2 = -np.sum( 1/_sqrt_2pi*np.dot( np.log(1+safe_exp(f)),w) )\n",
    "        term3 = np.sum( 1/_sqrt_2pi*np.dot( y*safe_ln(np.log(1+safe_exp(f))),w) )\n",
    "        vlb_lik = term1 + term2 + term3\n",
    "    vlb_kl = 0.5*( LogDetKmm - LogDetV + np.dot(c1.T, c2) + np.trace(np.dot(Kmm_inv,V)) - len(prior_mean_u) )\n",
    "    vlb = vlb_lik - vlb_kl\n",
    "    return vlb \n",
    "\n",
    "def get_init_hyperparameters(Z,Z_label,lik='Poisson',K='SE'):\n",
    "    # For all methods, initial variational parameters are found by running the Laplace approximation on the subset/active set.\n",
    "    dim_data = Z.shape[1]\n",
    "    if K=='SE': kern=GPy.kern.RBF(dim_data, variance=1.0, lengthscale=1.0);\n",
    "    elif K=='Matern32': kern=GPy.kern.Matern32(dim_data, variance=1.0, lengthscale=1.0);\n",
    "    elif K=='Matern52': kern=GPy.kern.Matern52(dim_data, variance=1.0, lengthscale=1.0);\n",
    "    \n",
    "    if lik=='Poisson': likelihood=GPy.likelihoods.Poisson();\n",
    "    elif lik=='Poisson2': likelihood=GPy.likelihoods.Poisson(GPy.likelihoods.link_functions.Log_ex_1());\n",
    "    elif lik=='Gaussian': likelihood=GPy.likelihoods.Gaussian();\n",
    "    elif lik=='Bernoulli': likelihood=GPy.likelihoods.Bernoulli();\n",
    "\n",
    "    laplace_inf = GPy.inference.latent_function_inference.Laplace()\n",
    "    model_lap = GPy.core.GP(X=Z, Y=Z_label, likelihood=likelihood, inference_method=laplace_inf, kernel=kern)\n",
    "    model_lap.optimize();\n",
    "    if K=='SE': length_scale=model_lap.rbf.lengthscale[0];signal_variance=model_lap.rbf.variance[0]\n",
    "    elif K=='Matern32': length_scale=model_lap.Mat32.lengthscale[0];signal_variance=model_lap.Mat32.variance[0]\n",
    "    elif K=='Matern52': length_scale=model_lap.Mat52.lengthscale[0];signal_variance=model_lap.Mat52.variance[0]\n",
    "    print(model_lap)\n",
    "    return model_lap,length_scale,signal_variance\n",
    "\n",
    "def Adam(theta, g_t, t, alpha=0.01, m_t=0, v_t=0, opt='minimize'):\n",
    "    beta_1 = 0.9; beta_2 = 0.999; epsilon = 1e-8     #initialize the values of the parameters    \n",
    "    m_t = beta_1*m_t + (1-beta_1)*g_t                #updates the moving averages of the gradient\n",
    "    v_t = beta_2*v_t + (1-beta_2)*(g_t*g_t)          #updates the moving averages of the squared gradient\n",
    "    m_cap = m_t/(1-(beta_1**t))                      #calculates the bias-corrected estimates\n",
    "    v_cap = v_t/(1-(beta_2**t))                      #calculates the bias-corrected estimates\n",
    "    if opt=='maximize':\n",
    "        theta = theta + (alpha*m_cap)/(np.sqrt(v_cap)+epsilon)    #updates the parameters\n",
    "    else:\n",
    "        theta = theta - (alpha*m_cap)/(np.sqrt(v_cap)+epsilon)    #updates the parameters\n",
    "    return theta, m_t, v_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GH_quad(mu_star,std_star): # gauss_hermite_quad to calculate numerical integration, w and z denote weights and sample points, respectively. \n",
    "    z,w = roots_hermitenorm(n=50, mu=False); z,w=z[:,None],w[:,None]\n",
    "    z = np.kron(std_star,z.T) + mu_star\n",
    "    return z,w\n",
    "\n",
    "def calc_err(X, xStar, yTrue, l, sigma2, m, V,Kmm,Kmm_inv,noise_var=0.1,lik='Poisson',K='SE'):\n",
    "    num_xStar = xStar.shape[0]; Kmn = kernel(X, xStar, l=l, sigma_f=np.sqrt(sigma2),K=K)\n",
    "    Knn_diag = kernel(xStar, l=l, sigma_f=np.sqrt(sigma2),K='diag')+noise_var*np.eye(num_xStar)#np.eye(num_xStar)*sigma2+noise_var*np.eye(num_xStar)\n",
    "    A = np.dot(Kmn.T, Kmm_inv);\n",
    "    mu_star = np.dot(A,m); v2_star = Knn_diag + np.dot(A, np.dot(V-Kmm,A.T))\n",
    "    std_star = np.sqrt(np.diag(v2_star))[:,None]\n",
    "    if lik=='Bernoulli':\n",
    "        p = calc_Bernoulli_pred(mu_star,std_star,yTrue); #res = np.where(p>=0.5,1,-1);print(min(p),max(p));\n",
    "#         nll = -np.sum(safe_ln((1-0.5/p)*yTrue+0.5));\n",
    "        nll = -np.sum(safe_ln(p))\n",
    "        err = np.sum( np.where(p<0.5,1,0) )/num_xStar\n",
    "#         err = np.sum( np.where(yTrue*res<0,1,0) )/num_xStar\n",
    "        return err,nll\n",
    "    elif lik=='Gaussian':\n",
    "        mu, std = calc_Gauss_pred(mu_star,std_star,noise_var)\n",
    "        err = np.sum( (yTrue-mu)**2 );\n",
    "#         nll=0.5*np.dot(np.dot((yTrue-mu).T,np.diag(1/(std**2).ravel())),yTrue-mu)+np.sum(np.log(std))+num_xStar/2*np.log(2*np.pi)\n",
    "        mse = 1/num_xStar*err;# print((yTrue-mu).shape);#print(std.shape);print(((yTrue-mu)/std).shape)        \n",
    "#         nll = np.sum(np.log(std))+num_xStar/2*np.log(2*np.pi)+1/2*np.sum(((yTrue-mu)/std)**2)\n",
    "        nll = 1/2*np.sum(((yTrue-mu)/std)**2)\n",
    "#         nll=0.5*np.dot(np.dot((yTrue-mu).T,np.diag(1/(std**2).ravel())),yTrue-mu)+0.5*np.log(np.diag((std**2).ravel())+num_xStar/2*np.log(2*np.pi)\n",
    "        return mse,nll\n",
    "    else: # Poisson, Poisson2\n",
    "        y_min = min(yTrue); y_max = max(yTrue); #print(y_min,y_max)\n",
    "        pmf = calc_Poisson_pred(mu_star,std_star,num_xStar,y_min,y_max,lik);#print(pmf.shape);#print(pmf[:3,:]);#print((yTrue-y_min).astype(int).shape)\n",
    "        nll = -np.sum(safe_ln(pmf[np.arange(len(pmf)),(yTrue-y_min).astype(int).ravel()]));#print(pmf[np.arange(len(pmf)),(yTrue-y_min).astype(int).ravel()])\n",
    "        res = np.argmax(pmf, axis=1)+y_min; err = MFE(yTrue, res)\n",
    "        return err,nll\n",
    "\n",
    "def calc_Gauss_pred(mu_star,std_star,noise_var):\n",
    "    return mu_star, std_star+np.sqrt(noise_var)\n",
    "\n",
    "def calc_Poisson_pred(mu_star,std_star,num_xStar,y_min,y_max,lik='Poisson'):\n",
    "    f,w = GH_quad(mu_star,std_star)\n",
    "    y_range = np.arange(y_min,y_max+1)\n",
    "    lik_func = {\n",
    "        'Poisson': lambda f,y: 1/gamma(y+1)*safe_exp(-safe_exp(f)+f*y),\n",
    "        'Poisson2': lambda f,y: 1/gamma(y+1)*expit(-f)*( safe_ln(1.0+safe_exp(f))**y )\n",
    "    }[lik]\n",
    "    poisson_lik = np.zeros((num_xStar,len(y_range)))\n",
    "    for i,y in enumerate(y_range):\n",
    "        poisson_lik[:,i] = 1/_sqrt_2pi*np.dot(lik_func(f,y),w).ravel()\n",
    "    return poisson_lik\n",
    "\n",
    "def calc_Bernoulli_pred(mu_star,std_star,y):\n",
    "#     v = std_star**2; kappa_v = (1+np.pi*v/8.0)**(-1/2) # Probit liklihood\n",
    "#     p = sigmoid(kappa_v*mu_star) # p(y=1|x_*,m,V)\n",
    "    f,w = GH_quad(mu_star,std_star) # sigmoid liklihood\n",
    "    p = 1/np.sqrt(2*np.pi)*np.dot( expit(f*y), w ) # p(y=1|x_*,m,V)\n",
    "    return p\n",
    "\n",
    "def calc_m_q(m, A, prior_u, prior_f):\n",
    "#     print(A.shape);print(m.shape)\n",
    "    return prior_f + np.dot(A, (m-prior_u))\n",
    "\n",
    "def calc_v_q(V, A, Kmm, Knn_diag):\n",
    "    return ( Knn_diag.ravel() + np.diag(np.dot(A, np.dot(V-Kmm, A.T))) )[:,None] # Eq.(3b) in paper\n",
    "\n",
    "def calc_rho(m_q, v_q, y, lik='Poisson', noise_var=0.1):\n",
    "    if lik=='Bernoulli':\n",
    "        f,w = GH_quad(m_q,np.sqrt(v_q))\n",
    "        return 1.0/_sqrt_2pi*np.dot(  y*expit(-y*f) , w ) # sigmoid liklihood\n",
    "#         return 1.0/_sqrt_2pi*np.dot( y*std_norm_pdf(f) / (std_norm_cdf(y*f)+1e-10), w ) # Probit liklihood        \n",
    "    elif lik=='Gaussian':\n",
    "        return 1.0/noise_var*(y-m_q)\n",
    "    elif lik=='Poisson':\n",
    "        return -np.exp(m_q + 0.5*v_q) + y\n",
    "    elif lik=='Poisson2':\n",
    "        f,w = GH_quad(m_q,np.sqrt(v_q))\n",
    "        y = np.tile(y,[1,f.shape[1]]); term2 = expit(f); t0 = safe_ln(1+safe_exp(f))# avoid dividing by zeros\n",
    "        d1_log_lik = np.zeros(t0.shape)\n",
    "        d1_log_lik[t0!=0] = (y[t0!=0]/t0[t0!=0] - 1)*term2[t0!=0]\n",
    "        return 1.0/_sqrt_2pi*np.dot(  d1_log_lik, w )\n",
    "    \n",
    "def calc_lambda(m_q, v_q, y, lik='Poisson', noise_var=0.1):\n",
    "    if lik=='Bernoulli':\n",
    "        f,w = GH_quad(m_q,np.sqrt(v_q))\n",
    "        return 1.0/np.sqrt(2*np.pi)*np.dot(  -expit(y*f)*expit(-y*f), w ) # sigmoid\n",
    "#         return 1.0/_sqrt_2pi*np.dot( -std_norm_pdf(f)**2 / (std_norm_cdf(y*f)**2+1e-10) - y*f*std_norm_pdf(f) / (std_norm_cdf(y*f)+1e-10), w )\n",
    "    elif lik=='Gaussian':\n",
    "        return -1.0/noise_var*np.ones((len(m_q),1))\n",
    "    elif lik=='Poisson':\n",
    "        return -np.exp(m_q + 0.5*v_q)\n",
    "    elif lik=='Poisson2':\n",
    "        f,w = GH_quad(m_q,np.sqrt(v_q));y = np.tile(y,[1,f.shape[1]]);\n",
    "        term2 = expit(f)*expit(f); t0 = safe_ln(1+safe_exp(f));d2_log_lik = np.zeros(t0.shape)\n",
    "        d2_log_lik[t0!=0] = ((y[t0!=0]/t0[t0!=0]-1)*safe_exp(-f[t0!=0])-y[t0!=0]/(t0[t0!=0])**2)*term2[t0!=0]\n",
    "        return 1.0/_sqrt_2pi*np.dot(  d2_log_lik, w )\n",
    "\n",
    "def dVLb_dm(m, rho, prior_mean_u, Kmm_inv, A,batch_size=None,num_train=None):\n",
    "    if batch_size is None: coef=1\n",
    "    else: coef=num_train/batch_size\n",
    "    dm = np.dot(A.T,rho)*coef - np.dot(Kmm_inv, m-prior_mean_u) # Eq.(11a) in paper\n",
    "    return dm\n",
    "\n",
    "def dVLb_dL(L, lam, Kmm_inv, A, noise_var=1e-8,batch_size=None,num_train=None):# optimizing the cholesky factor L guarantees the PSD of V automatically\n",
    "    if batch_size is None: coef=1\n",
    "    else: coef=num_train/batch_size\n",
    "    dL = np.dot( np.dot( np.dot(A.T, np.diag(lam.ravel())), A ), L )*coef + inv(L+np.sqrt(noise_var)*np.eye(len(L))).T - np.dot(Kmm_inv, L)\n",
    "    return dL\n",
    "\n",
    "def SDSVI(X,Y,Kmm,Kmm_inv,Kmn,Knn_diag,m,L,V,prior_u,prior_f,noise_var,var,num_inducing,num_iter,lr,m_t,v_t,lik,batch_size=500):\n",
    "    num_train=X.shape[0];\n",
    "    indx = random.sample(range(num_train),batch_size);\n",
    "    Xb = X[indx, :]; Yb_label = Y[indx];prior_f=prior_f[indx]\n",
    "    rows=np.arange(num_inducing); cols=np.asarray(indx, dtype=np.intp)\n",
    "    Kmn_sto=Kmn[np.ix_(rows, cols)]; A = np.dot(Kmn_sto.T, Kmm_inv);\n",
    "    Knn_diag=Knn_diag[cols];\n",
    "    m_q = calc_m_q(m, A, prior_u, prior_f); v_q = calc_v_q(V, A, Kmm, Knn_diag);\n",
    "    rho = calc_rho(m_q, v_q,Yb_label,lik, noise_var); lam = calc_lambda(m_q, v_q,Yb_label,lik, noise_var)\n",
    "#     rho = rho[cols]; lam = lam[cols];\n",
    "    var = np.hstack([m.flatten(), L.flatten()])\n",
    "    dm = dVLb_dm(m, rho, prior_u, Kmm_inv, A,batch_size,num_train)\n",
    "    dL = dVLb_dL(L, lam, Kmm_inv, A, noise_var,batch_size,num_train)\n",
    "    gradients = np.hstack([dm.flatten(), dL.flatten()])\n",
    "    var, m_t, v_t = Adam(var,gradients,num_iter,lr,m_t,v_t,opt='maximize')\n",
    "    m = var[:num_inducing][:,None] # variantional mean\n",
    "    L = var[num_inducing:].reshape(num_inducing,num_inducing) # variational variance V=L*L.T\n",
    "    V = np.dot(L, L.T)\n",
    "    return m,L,V,m_t,v_t\n",
    "\n",
    "def SDSVI1(X,Y,Z,ls,sf2,K,Kmm,Kmm_inv,m,L,V,prior_u,prior_f,noise_var,num_inducing,num_iter,lr,m_t,v_t,lik,batch_size=500):\n",
    "    num_train=X.shape[0];    \n",
    "    indx = random.sample(range(num_train),batch_size);\n",
    "    Xb = X[indx, :]; Yb_label = Y[indx];prior_f=prior_f[indx]\n",
    "    Kmn=kernel(Z, Xb, l = ls, sigma_f = np.sqrt(sf2),K=K);\n",
    "    Knn_diag =kernel(Xb, l = ls, sigma_f = np.sqrt(sf2),K='diag');\n",
    "    A = np.dot(Kmn.T, Kmm_inv) # Knm*inv(Kmm)\n",
    "    m_q = calc_m_q(m, A, prior_u, prior_f); v_q = calc_v_q(V, A, Kmm, Knn_diag);\n",
    "    rho = calc_rho(m_q, v_q, Yb_label,lik, noise_var); lam = calc_lambda(m_q, v_q,Yb_label,lik, noise_var);\n",
    "    dm = dVLb_dm(m, rho, prior_u, Kmm_inv, A,batch_size,num_train)\n",
    "    dL = dVLb_dL(L, lam, Kmm_inv, A, noise_var,batch_size,num_train)\n",
    "    gradients = np.hstack([dm.flatten(), dL.flatten()]);var = np.hstack([m.flatten(), L.flatten()])\n",
    "    var, m_t, v_t = Adam(var,gradients,num_iter,lr,m_t, v_t,opt='maximize')\n",
    "    m = var[:num_inducing][:,None] # variantional mean\n",
    "    L = var[num_inducing:].reshape(num_inducing,num_inducing) # variational variance V=L*L.T\n",
    "    V = np.dot(L, L.T)\n",
    "    return m,L,V,m_t,v_t\n",
    "\n",
    "def MCSSVI(X,Y,Kmm,Kmm_inv,Kmn,Knn_diag,m,V,prior_u,prior_f,noise_var,var,num_inducing,num_iter,lik,batch_size=500):\n",
    "    num_train=X.shape[0];\n",
    "    indx = random.sample(range(num_train),batch_size);\n",
    "    Xb = X[indx, :]; Yb_label = Y[indx];prior_f=prior_f[indx]\n",
    "    rows=np.arange(num_inducing); cols=np.asarray(indx, dtype=np.intp)\n",
    "    Kmn_sto=Kmn[np.ix_(rows, cols)]; A = np.dot(Kmn_sto.T, Kmm_inv);\n",
    "    Knn_diag=Knn_diag[cols];\n",
    "    m_q = calc_m_q(m, A, prior_u, prior_f); v_q = calc_v_q(V, A, Kmm, Knn_diag);\n",
    "    rho = calc_rho(m_q, v_q,Yb_label,lik, noise_var); lam = calc_lambda(m_q, v_q,Yb_label,lik, noise_var)\n",
    "    d = A.T; gamma = -lam; #print('old m:',m[:1]); print('old V:',V[:2,:2])\n",
    "    step_size = num_iter**(-1);#V_old=V\n",
    "    interm_V = Kmm_inv+ num_train/batch_size * np.dot( np.dot(A.T, np.diag(gamma.ravel())), A) #intermediate parameter\n",
    "    V = inv( (1-step_size)*V + step_size*interm_V )\n",
    "    interm_m = num_train/batch_size * np.dot(d, rho + np.dot(A,m)*gamma)\n",
    "    m = (1-step_size)*m + step_size*np.dot(V, interm_m ) # assume prior_u=0\n",
    "#     m = (1-step_size)*np.dot(V,np.dot(inv(V_old),m)) + step_size*np.dot(V, interm_m ) # assume prior_u=0\n",
    "#     m = np.dot(V, num_train/batch_size * np.dot(d, rho + np.dot(A,m)*gamma) );\n",
    "    return m,V\n",
    "\n",
    "def HMCSSVI(X,Y,Kmm,Kmm_inv,Kmn,Knn_diag,m,V,prior_u,prior_f,noise_var,var,num_inducing,num_iter,lr,m_t,v_t,lik,batch_size=500):\n",
    "    num_train=X.shape[0];\n",
    "    indx = random.sample(range(num_train),batch_size);\n",
    "    Xb = X[indx, :]; Yb_label = Y[indx];prior_f=prior_f[indx]\n",
    "    rows=np.arange(num_inducing); cols=np.asarray(indx, dtype=np.intp)\n",
    "    Kmn_sto=Kmn[np.ix_(rows, cols)]; A = np.dot(Kmn_sto.T, Kmm_inv); Knn_diag=Knn_diag[cols];\n",
    "    m_q = calc_m_q(m, A, prior_u, prior_f); v_q = calc_v_q(V, A, Kmm, Knn_diag);\n",
    "    rho = calc_rho(m_q, v_q,Yb_label,lik, noise_var); lam = calc_lambda(m_q, v_q,Yb_label,lik, noise_var)\n",
    "    d = A.T; gamma = -lam; #print('old m:',m[:1]); print('old V:',V[:2,:2])\n",
    "    step_size = num_iter**(-1);#V_old=V\n",
    "    interm_V = Kmm_inv+ num_train/batch_size * np.dot( np.dot(A.T, np.diag(gamma.ravel())), A) #intermediate parameter\n",
    "    V = inv( (1-step_size)*V + step_size*interm_V )\n",
    "    dm = dVLb_dm(m, rho, prior_u, Kmm_inv, A,batch_size,num_train)\n",
    "    m, m_t, v_t = Adam(m,dm,num_iter,lr,m_t, v_t,opt='maximize')\n",
    "#     m = (1-step_size)*np.dot(V,np.dot(inv(V_old),m)) + step_size*np.dot(V, interm_m ) # assume prior_u=0\n",
    "#     m = np.dot(V, num_train/batch_size * np.dot(d, rho + np.dot(A,m)*gamma) );\n",
    "    return m,V,m_t,v_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(X,Y,ix,X_test=None,y_test=None,max_iter=100,lr=1*10**-5,FPb_cond=1*10**0,stop_cond=1*10**-5,VLB_opt='GD',lik='Poisson',K='SE'):\n",
    "    num_train = X.shape[0];num_inducing=len(ix);num_test=X_test.shape[0]; \n",
    "    prior_u = np.zeros((num_inducing, 1)); prior_f = np.zeros((num_train, 1))\n",
    "    Z = X[ix, :]; Z_label = Y[ix] # Z is the inducing set\n",
    "    model_lap,ls,sf2 = get_init_hyperparameters(Z,Z_label,lik=lik,K=K)#(Z_label+1)/2    \n",
    "    # variational parameters from initialization\n",
    "    f_mean, f_var = model_lap._raw_predict(X) ; #print(ls,sf2)\n",
    "#     ls = model_lap.rbf.lengthscale[0]; sf2 = model_lap.rbf.variance[0]; # length_scale,sigma_f2\n",
    "    if lik=='Gaussian': noise_var=model_lap.Gaussian_noise.variance[0] \n",
    "    else: noise_var=1*10**-8\n",
    "    #  we use variational mean from Laplace appr\n",
    "    m = f_mean[ix]; V = np.diag(f_var[ix].ravel()); L = cholesky(V);#print(min(f_var))\n",
    "    Kmm = kernel(Z, Z, l = ls, sigma_f = np.sqrt(sf2),K=K) + noise_var*np.eye(len(Z))\n",
    "    Kmm_inv = inv(Kmm); Kmn = kernel(Z, X, l = ls, sigma_f = np.sqrt(sf2),K=K); \n",
    "    Knn_diag =kernel(X, l = ls, sigma_f = np.sqrt(sf2),K='diag'); #sf2*np.ones((num_train, 1))\n",
    "    A = np.dot(Kmn.T, Kmm_inv) # Knm*inv(Kmm)    \n",
    "    a = (prior_u,prior_f,A,Kmm,Kmm_inv,Kmn,Knn_diag,Y,noise_var)\n",
    "    num_iter = 0; VLB = []; VLB_time = []; err = []; nll=[]; FPb_converge = False# True\n",
    "    var = np.hstack([m.flatten(), L.flatten()])\n",
    "    start_time = time.time(); VLB.append(-calc_vlb(m,V, a,lik)[0][0]);\n",
    "    res = calc_err(Z,X_test,y_test,ls,sf2,m,V,Kmm,Kmm_inv,noise_var=noise_var,lik=lik,K=K)\n",
    "    err.append(res[0]); nll.append(res[1]);\n",
    "    VLB_time.append(time.time()-start_time);print('Before iterations, VLB:{:.6f} err:{:.6f}, nll:{:.6f}'.format(VLB[-1],err[-1],nll[-1]) )\n",
    "    m_t=0; v_t=0;batch_size=10\n",
    "    while 1:\n",
    "        num_iter = num_iter +1;#break\n",
    "        if VLB_opt in ['GD','FPi','FPb','FPi-mean']:\n",
    "            m_q = calc_m_q(m, A, prior_u, prior_f); v_q = calc_v_q(V, A, Kmm, Knn_diag);#print('m_q:',m_q[:10])\n",
    "            # According to Table 1 in paper, expectations of the derivatives wrt N(f|m,v) for Possion likelihood\n",
    "            rho = calc_rho(m_q, v_q, Y,lik, noise_var); lam = calc_lambda(m_q, v_q,Y,lik, noise_var);\n",
    "        if VLB_opt=='SDSVI1':\n",
    "            m,L,V,m_t,v_t = SDSVI1(X,Y,Z,ls,sf2,K,Kmm_inv,m,L,V,prior_u,prior_f,noise_var,num_inducing,num_iter,lr,m_t,v_t,lik,batch_size)\n",
    "            \n",
    "        if VLB_opt=='SDSVI':\n",
    "            m,L,V,m_t,v_t=SDSVI(X,Y,Kmm,Kmm_inv,Kmn,Knn_diag,m,L,V,prior_u,prior_f,noise_var,var,num_inducing,num_iter,lr,m_t,v_t,lik,batch_size)\n",
    "            \n",
    "        if VLB_opt=='MCSSVI':\n",
    "            m,V=MCSSVI(X,Y,Kmm,Kmm_inv,Kmn,Knn_diag,m,V,prior_u,prior_f,noise_var,var,num_inducing,num_iter,lik,batch_size)\n",
    "        if VLB_opt=='HMCSSVI':\n",
    "            m,V,m_t,v_t=HMCSSVI(X,Y,Kmm,Kmm_inv,Kmn,Knn_diag,m,V,prior_u,prior_f,noise_var,var,num_inducing,num_iter,lr,m_t,v_t,lik,batch_size)\n",
    "        \n",
    "        if VLB_opt=='GD':\n",
    "            dm = dVLb_dm(m, rho, prior_u, Kmm_inv, A); dL = dVLb_dL(L, lam, Kmm_inv, A, noise_var)\n",
    "            gradients = np.hstack([dm.flatten(), dL.flatten()])\n",
    "            var, m_t, v_t = Adam(var,gradients,num_iter,lr,m_t, v_t,opt='maximize')\n",
    "            m = var[:num_inducing][:,None] # variantional mean\n",
    "            L = var[num_inducing:].reshape(num_inducing,num_inducing) # variational variance V=L*L.T\n",
    "            V = np.dot(L, L.T);\n",
    "            \n",
    "        elif VLB_opt=='FPi':\n",
    "            dm = dVLb_dm(m, rho, prior_u, Kmm_inv, A)\n",
    "            m, m_t, v_t = Adam(m,dm,num_iter,lr,m_t, v_t,opt='maximize') # print('old V',V[:1,:1])\n",
    "            V = inv(Kmm_inv-np.dot( np.dot(A.T, np.diag(lam.ravel())), A ));\n",
    "        elif VLB_opt=='FPb':            \n",
    "            if FPb_converge:\n",
    "                dm = dVLb_dm(m, rho, prior_u, Kmm_inv, A); #print('old m:',m[:1]);\n",
    "                m, m_t, v_t = Adam(m,dm,num_iter,lr,m_t, v_t,opt='maximize')\n",
    "            else:\n",
    "                V = inv(Kmm_inv-np.dot( np.dot(A.T, np.diag(lam.ravel())), A))\n",
    "                \n",
    "        elif VLB_opt=='FPi-mean':\n",
    "            d = A.T; gamma = -lam; #print('old m:',m[:1]); print('old V:',V[:2,:2])\n",
    "            V = inv(Kmm_inv+np.dot( np.dot(A.T, np.diag(gamma.ravel())), A))\n",
    "#             V = inv(Kmm_inv-np.dot( np.dot(A.T, np.diag(lam.ravel())), A))\n",
    "            m = np.dot(V, np.dot(d, rho + np.dot(A,m)*gamma) );\n",
    "\n",
    "        VLB.append(-calc_vlb(m,V, a,lik)[0][0]); VLB_time.append(time.time()-start_time)\n",
    "        res = calc_err(Z,X_test,y_test,ls,sf2,m,V,Kmm,Kmm_inv,noise_var=noise_var,lik=lik,K=K)\n",
    "        err.append(res[0]); nll.append(res[1])\n",
    "        if num_iter>0:\n",
    "            delta_vlb = abs(VLB[-1]-VLB[-2])\n",
    "            if num_iter%1 == 0:\n",
    "                print('iter:{}, delta_VLB:{:.6f}, negVLB:{:.6f}, err:{:.6f}, nll:{:.6f}'.format(num_iter, VLB[-2]-VLB[-1], VLB[-1], err[-1],nll[-1]));\n",
    "            if VLB_opt=='FPb' and delta_vlb<=FPb_cond:\n",
    "                FPb_converge = not FPb_converge; #print('m or V converged')\n",
    "            if num_iter>5 and delta_vlb<=stop_cond:\n",
    "                if np.average(VLB[-2:])<np.average(VLB[-4:]):\n",
    "                    if num_iter>=max_iter: print('It has reached the maximum number of iterations.');break\n",
    "                    else:continue\n",
    "                else: print('After {} iterations it converged: delta_VLB:{:.6f}, negVLB:{:.6f}, err:{:.6f}'.format(num_iter,delta_vlb,VLB[-1],err[-1]) );break                \n",
    "            if num_iter>22 and np.average(VLB[-6:])>=np.average(VLB[-12:]): print('negVLB did not decrease any more.'); break;            \n",
    "            elif num_iter==max_iter:\n",
    "                print('It has reached the maximum number of iterations, i.e. {}, with delta_VLB:{:.6f}, negVLB:{:.6f} and err:{:.6f}'.format(max_iter,delta_vlb,VLB[-1],err[-1]));break            \n",
    "    return Z,Z_label, VLB, ls, sf2, m, V,noise_var, Kmm, Kmm_inv, A,VLB_time,err,nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name : gp\n",
      "Objective : 459.10391982352337\n",
      "Number of Parameters : 2\n",
      "Number of Optimization Parameters : 2\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mgp.              \u001b[0;0m  |              value  |  constraints  |  priors\n",
      "  \u001b[1mMat52.variance   \u001b[0;0m  |  297.5487109425978  |      +ve      |        \n",
      "  \u001b[1mMat52.lengthscale\u001b[0;0m  |  68.51895321692969  |      +ve      |        \n",
      "Before iterations, VLB:8083.693181 err:0.095661, nll:1911.969069\n",
      "iter:1, delta_VLB:-43755.271759, negVLB:51838.964940, err:0.173005, nll:2620.969336\n",
      "iter:2, delta_VLB:6611.120946, negVLB:45227.843994, err:0.132962, nll:2586.262705\n",
      "iter:3, delta_VLB:-13884.544631, negVLB:59112.388625, err:0.191476, nll:2694.512141\n",
      "iter:4, delta_VLB:-10867.237586, negVLB:69979.626211, err:0.222624, nll:2770.462708\n",
      "iter:5, delta_VLB:-11196.451581, negVLB:81176.077792, err:0.273114, nll:2849.495826\n",
      "iter:6, delta_VLB:-8527.988292, negVLB:89704.066084, err:0.289623, nll:2892.207009\n",
      "iter:7, delta_VLB:-3363.983357, negVLB:93068.049441, err:0.298807, nll:2910.653784\n",
      "iter:8, delta_VLB:-2236.682210, negVLB:95304.731651, err:0.307648, nll:2921.569713\n",
      "iter:9, delta_VLB:-3583.346483, negVLB:98888.078134, err:0.324722, nll:2943.411574\n",
      "iter:10, delta_VLB:2510.979413, negVLB:96377.098720, err:0.337299, nll:2940.371121\n",
      "iter:11, delta_VLB:4289.367187, negVLB:92087.731533, err:0.349536, nll:2931.427041\n",
      "iter:12, delta_VLB:4020.141384, negVLB:88067.590150, err:0.365699, nll:2922.960633\n",
      "iter:13, delta_VLB:3643.012987, negVLB:84424.577162, err:0.382397, nll:2924.761660\n",
      "iter:14, delta_VLB:1402.653226, negVLB:83021.923937, err:0.400986, nll:2935.643057\n",
      "iter:15, delta_VLB:-724.588049, negVLB:83746.511986, err:0.423652, nll:2957.586131\n",
      "iter:16, delta_VLB:800.902211, negVLB:82945.609774, err:0.431193, nll:2974.200194\n",
      "iter:17, delta_VLB:94.885130, negVLB:82850.724644, err:0.450072, nll:2992.824864\n",
      "iter:18, delta_VLB:10.308815, negVLB:82840.415829, err:0.451861, nll:3009.764864\n",
      "iter:19, delta_VLB:-259.156967, negVLB:83099.572796, err:0.456846, nll:3026.952428\n",
      "iter:20, delta_VLB:122.359692, negVLB:82977.213104, err:0.464825, nll:3042.086992\n",
      "iter:21, delta_VLB:1100.852277, negVLB:81876.360828, err:0.475996, nll:3053.536615\n",
      "iter:22, delta_VLB:1777.369344, negVLB:80098.991483, err:0.492379, nll:3060.918842\n",
      "iter:23, delta_VLB:1805.222452, negVLB:78293.769032, err:0.505504, nll:3070.520022\n",
      "iter:24, delta_VLB:1739.751682, negVLB:76554.017349, err:0.521213, nll:3077.394383\n",
      "iter:25, delta_VLB:2406.291986, negVLB:74147.725363, err:0.538770, nll:3082.935539\n",
      "iter:26, delta_VLB:3059.579552, negVLB:71088.145811, err:0.550569, nll:3087.767932\n",
      "iter:27, delta_VLB:2633.196094, negVLB:68454.949717, err:0.573020, nll:3093.109547\n",
      "iter:28, delta_VLB:2701.041798, negVLB:65753.907919, err:0.600848, nll:3101.024742\n",
      "iter:29, delta_VLB:2913.796493, negVLB:62840.111426, err:0.631175, nll:3110.919070\n",
      "iter:30, delta_VLB:2298.875748, negVLB:60541.235678, err:0.661281, nll:3113.267063\n",
      "iter:31, delta_VLB:1766.208919, negVLB:58775.026760, err:0.683889, nll:3113.532760\n",
      "iter:32, delta_VLB:1202.985518, negVLB:57572.041241, err:0.696231, nll:3122.318636\n",
      "iter:33, delta_VLB:1615.085270, negVLB:55956.955971, err:0.719108, nll:3135.683257\n",
      "iter:34, delta_VLB:459.401766, negVLB:55497.554205, err:0.729832, nll:3149.589236\n",
      "iter:35, delta_VLB:232.559381, negVLB:55264.994824, err:0.740174, nll:3160.310513\n",
      "iter:36, delta_VLB:69.010048, negVLB:55195.984775, err:0.746245, nll:3169.723920\n",
      "iter:37, delta_VLB:335.711137, negVLB:54860.273639, err:0.751915, nll:3179.980463\n",
      "iter:38, delta_VLB:470.490245, negVLB:54389.783394, err:0.766551, nll:3189.755192\n",
      "iter:39, delta_VLB:402.155220, negVLB:53987.628174, err:0.770981, nll:3197.030507\n",
      "iter:40, delta_VLB:1107.892688, negVLB:52879.735487, err:0.777439, nll:3202.647110\n",
      "iter:41, delta_VLB:828.283364, negVLB:52051.452123, err:0.780111, nll:3211.812112\n",
      "iter:42, delta_VLB:775.686981, negVLB:51275.765142, err:0.787831, nll:3221.480453\n",
      "iter:43, delta_VLB:1317.847911, negVLB:49957.917230, err:0.785344, nll:3229.850620\n",
      "iter:44, delta_VLB:1099.570996, negVLB:48858.346234, err:0.784345, nll:3236.411057\n",
      "iter:45, delta_VLB:1257.472719, negVLB:47600.873515, err:0.791282, nll:3242.925632\n",
      "iter:46, delta_VLB:877.168066, negVLB:46723.705449, err:0.796717, nll:3246.698398\n",
      "iter:47, delta_VLB:1046.900275, negVLB:45676.805173, err:0.798695, nll:3249.371542\n",
      "iter:48, delta_VLB:1089.044405, negVLB:44587.760768, err:0.799256, nll:3252.960038\n",
      "iter:49, delta_VLB:1344.793099, negVLB:43242.967669, err:0.801463, nll:3250.252451\n",
      "iter:50, delta_VLB:1064.772768, negVLB:42178.194901, err:0.799831, nll:3250.316104\n",
      "iter:51, delta_VLB:1167.726238, negVLB:41010.468663, err:0.802667, nll:3249.902273\n",
      "iter:52, delta_VLB:899.268216, negVLB:40111.200447, err:0.800537, nll:3244.089021\n",
      "iter:53, delta_VLB:942.297451, negVLB:39168.902996, err:0.799025, nll:3240.847850\n",
      "iter:54, delta_VLB:451.357620, negVLB:38717.545377, err:0.794492, nll:3234.154072\n",
      "iter:55, delta_VLB:269.699998, negVLB:38447.845379, err:0.790174, nll:3226.726796\n",
      "iter:56, delta_VLB:377.844300, negVLB:38070.001079, err:0.788301, nll:3219.568393\n",
      "iter:57, delta_VLB:507.954182, negVLB:37562.046897, err:0.780090, nll:3215.355717\n",
      "iter:58, delta_VLB:860.607952, negVLB:36701.438945, err:0.777285, nll:3214.424552\n",
      "iter:59, delta_VLB:846.029369, negVLB:35855.409577, err:0.773775, nll:3214.323077\n",
      "iter:60, delta_VLB:921.878750, negVLB:34933.530827, err:0.770005, nll:3214.554499\n",
      "iter:61, delta_VLB:588.344917, negVLB:34345.185910, err:0.758277, nll:3213.603728\n",
      "iter:62, delta_VLB:363.805181, negVLB:33981.380729, err:0.748818, nll:3210.127433\n",
      "iter:63, delta_VLB:478.319982, negVLB:33503.060747, err:0.758145, nll:3203.816192\n",
      "iter:64, delta_VLB:445.076581, negVLB:33057.984166, err:0.755634, nll:3191.281074\n",
      "iter:65, delta_VLB:265.528212, negVLB:32792.455954, err:0.750969, nll:3178.578936\n",
      "iter:66, delta_VLB:333.049469, negVLB:32459.406485, err:0.743090, nll:3167.732425\n",
      "iter:67, delta_VLB:297.142849, negVLB:32162.263637, err:0.736246, nll:3157.977257\n",
      "iter:68, delta_VLB:195.142647, negVLB:31967.120990, err:0.731645, nll:3148.501085\n",
      "iter:69, delta_VLB:237.063799, negVLB:31730.057192, err:0.723317, nll:3139.254460\n",
      "iter:70, delta_VLB:356.406817, negVLB:31373.650375, err:0.715501, nll:3128.668451\n",
      "iter:71, delta_VLB:198.593909, negVLB:31175.056466, err:0.709473, nll:3117.734788\n",
      "iter:72, delta_VLB:99.874473, negVLB:31075.181993, err:0.703014, nll:3105.681728\n",
      "iter:73, delta_VLB:53.720911, negVLB:31021.461082, err:0.696836, nll:3091.815044\n",
      "iter:74, delta_VLB:55.517216, negVLB:30965.943866, err:0.689342, nll:3079.818020\n",
      "iter:75, delta_VLB:-13.300820, negVLB:30979.244685, err:0.682483, nll:3068.259624\n",
      "iter:76, delta_VLB:332.160888, negVLB:30647.083798, err:0.683907, nll:3060.090352\n",
      "iter:77, delta_VLB:351.964645, negVLB:30295.119153, err:0.680183, nll:3048.523119\n",
      "iter:78, delta_VLB:348.495059, negVLB:29946.624094, err:0.668779, nll:3038.033957\n",
      "iter:79, delta_VLB:228.591757, negVLB:29718.032337, err:0.661306, nll:3027.947579\n",
      "iter:80, delta_VLB:242.377599, negVLB:29475.654738, err:0.653890, nll:3018.996307\n",
      "iter:81, delta_VLB:372.521629, negVLB:29103.133109, err:0.649691, nll:3012.792573\n",
      "iter:82, delta_VLB:398.128434, negVLB:28705.004676, err:0.643302, nll:3005.924115\n",
      "iter:83, delta_VLB:528.658578, negVLB:28176.346098, err:0.641260, nll:3001.111055\n",
      "iter:84, delta_VLB:504.284933, negVLB:27672.061165, err:0.638911, nll:2997.777217\n",
      "iter:85, delta_VLB:594.003885, negVLB:27078.057280, err:0.628870, nll:2991.816471\n",
      "iter:86, delta_VLB:520.525585, negVLB:26557.531695, err:0.626878, nll:2981.760571\n",
      "iter:87, delta_VLB:588.495151, negVLB:25969.036544, err:0.627739, nll:2967.107272\n",
      "iter:88, delta_VLB:571.319102, negVLB:25397.717441, err:0.623152, nll:2949.040088\n",
      "iter:89, delta_VLB:357.115213, negVLB:25040.602228, err:0.618456, nll:2930.633697\n",
      "iter:90, delta_VLB:254.381259, negVLB:24786.220969, err:0.612673, nll:2911.052832\n",
      "iter:91, delta_VLB:129.577383, negVLB:24656.643586, err:0.606667, nll:2892.162453\n",
      "iter:92, delta_VLB:163.939306, negVLB:24492.704280, err:0.598957, nll:2875.141271\n",
      "iter:93, delta_VLB:135.690706, negVLB:24357.013575, err:0.597879, nll:2861.637157\n",
      "iter:94, delta_VLB:36.428008, negVLB:24320.585567, err:0.592173, nll:2848.818245\n",
      "iter:95, delta_VLB:340.806808, negVLB:23979.778759, err:0.582943, nll:2833.216678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:96, delta_VLB:589.399182, negVLB:23390.379576, err:0.577993, nll:2816.515277\n",
      "iter:97, delta_VLB:499.632375, negVLB:22890.747201, err:0.570793, nll:2801.253845\n",
      "iter:98, delta_VLB:302.112879, negVLB:22588.634322, err:0.568625, nll:2791.852343\n",
      "iter:99, delta_VLB:9.627362, negVLB:22579.006960, err:0.562644, nll:2785.166537\n",
      "iter:100, delta_VLB:-208.124399, negVLB:22787.131359, err:0.556602, nll:2777.173382\n",
      "iter:101, delta_VLB:-153.426274, negVLB:22940.557633, err:0.550980, nll:2768.603121\n",
      "iter:102, delta_VLB:-231.584188, negVLB:23172.141820, err:0.542828, nll:2757.987741\n",
      "iter:103, delta_VLB:-156.024315, negVLB:23328.166135, err:0.534689, nll:2744.790113\n",
      "iter:104, delta_VLB:-223.568037, negVLB:23551.734172, err:0.526799, nll:2731.043856\n",
      "iter:105, delta_VLB:-29.427770, negVLB:23581.161942, err:0.519334, nll:2715.419063\n",
      "iter:106, delta_VLB:267.631020, negVLB:23313.530922, err:0.517709, nll:2698.765056\n",
      "negVLB did not decrease any more.\n",
      "\n",
      "Name : gp\n",
      "Objective : 459.10391982352337\n",
      "Number of Parameters : 2\n",
      "Number of Optimization Parameters : 2\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mgp.              \u001b[0;0m  |              value  |  constraints  |  priors\n",
      "  \u001b[1mMat52.variance   \u001b[0;0m  |  297.5487109425978  |      +ve      |        \n",
      "  \u001b[1mMat52.lengthscale\u001b[0;0m  |  68.51895321692969  |      +ve      |        \n",
      "Before iterations, VLB:8083.693181 err:0.095661, nll:1911.969069\n",
      "iter:1, delta_VLB:-45923.434839, negVLB:54007.128021, err:0.127844, nll:2681.266078\n",
      "iter:2, delta_VLB:43611.329140, negVLB:10395.798880, err:0.089774, nll:2081.472281\n",
      "iter:3, delta_VLB:-5133.318025, negVLB:15529.116906, err:0.114205, nll:2308.024067\n",
      "iter:4, delta_VLB:-13961.470427, negVLB:29490.587333, err:0.152845, nll:2553.080862\n",
      "iter:5, delta_VLB:3406.886459, negVLB:26083.700874, err:0.205598, nll:2536.191859\n",
      "iter:6, delta_VLB:8393.962373, negVLB:17689.738501, err:0.273897, nll:2419.771924\n",
      "iter:7, delta_VLB:2847.360367, negVLB:14842.378134, err:0.340593, nll:2365.914559\n",
      "iter:8, delta_VLB:-125.806798, negVLB:14968.184932, err:0.387265, nll:2404.777961\n",
      "iter:9, delta_VLB:-1357.887500, negVLB:16326.072433, err:0.414459, nll:2473.494852\n",
      "iter:10, delta_VLB:-1803.425217, negVLB:18129.497650, err:0.435137, nll:2538.430350\n",
      "iter:11, delta_VLB:-1023.713946, negVLB:19153.211596, err:0.458823, nll:2577.773111\n",
      "iter:12, delta_VLB:333.158144, negVLB:18820.053452, err:0.476407, nll:2590.234360\n",
      "iter:13, delta_VLB:1080.358454, negVLB:17739.694997, err:0.491090, nll:2589.640368\n",
      "iter:14, delta_VLB:1094.131389, negVLB:16645.563609, err:0.505282, nll:2590.537096\n",
      "iter:15, delta_VLB:848.921932, negVLB:15796.641677, err:0.511013, nll:2594.696278\n",
      "iter:16, delta_VLB:608.431624, negVLB:15188.210053, err:0.506562, nll:2592.688772\n",
      "iter:17, delta_VLB:428.168272, negVLB:14760.041781, err:0.497156, nll:2578.217443\n",
      "iter:18, delta_VLB:313.257554, negVLB:14446.784227, err:0.482439, nll:2554.187105\n",
      "iter:19, delta_VLB:306.344388, negVLB:14140.439839, err:0.462859, nll:2525.436021\n",
      "iter:20, delta_VLB:378.586841, negVLB:13761.852998, err:0.437758, nll:2493.409239\n",
      "iter:21, delta_VLB:484.580564, negVLB:13277.272434, err:0.414005, nll:2457.189219\n",
      "iter:22, delta_VLB:575.979336, negVLB:12701.293098, err:0.387361, nll:2415.913095\n",
      "iter:23, delta_VLB:606.410881, negVLB:12094.882216, err:0.357874, nll:2369.904055\n",
      "iter:24, delta_VLB:585.766568, negVLB:11509.115648, err:0.327439, nll:2320.473114\n",
      "iter:25, delta_VLB:526.818202, negVLB:10982.297446, err:0.295309, nll:2269.396082\n",
      "iter:26, delta_VLB:448.000567, negVLB:10534.296880, err:0.259727, nll:2218.778056\n",
      "iter:27, delta_VLB:372.716338, negVLB:10161.580541, err:0.225730, nll:2171.025389\n",
      "iter:28, delta_VLB:302.839636, negVLB:9858.740905, err:0.189772, nll:2128.276120\n",
      "iter:29, delta_VLB:249.432168, negVLB:9609.308737, err:0.162763, nll:2091.401468\n",
      "iter:30, delta_VLB:221.193354, negVLB:9388.115382, err:0.134872, nll:2059.696787\n",
      "iter:31, delta_VLB:209.005576, negVLB:9179.109807, err:0.115839, nll:2031.749811\n",
      "iter:32, delta_VLB:197.117943, negVLB:8981.991864, err:0.099728, nll:2006.863449\n",
      "iter:33, delta_VLB:174.243685, negVLB:8807.748179, err:0.087230, nll:1985.516948\n",
      "iter:34, delta_VLB:138.881101, negVLB:8668.867078, err:0.082458, nll:1968.626838\n",
      "iter:35, delta_VLB:100.510657, negVLB:8568.356422, err:0.081062, nll:1956.697446\n",
      "iter:36, delta_VLB:68.644724, negVLB:8499.711697, err:0.083387, nll:1949.426735\n",
      "iter:37, delta_VLB:45.657806, negVLB:8454.053892, err:0.087958, nll:1945.750419\n",
      "iter:38, delta_VLB:33.368202, negVLB:8420.685690, err:0.092648, nll:1944.175300\n",
      "iter:39, delta_VLB:28.807965, negVLB:8391.877725, err:0.098655, nll:1943.338790\n",
      "iter:40, delta_VLB:31.084522, negVLB:8360.793203, err:0.103917, nll:1942.522894\n",
      "iter:41, delta_VLB:31.213480, negVLB:8329.579722, err:0.105909, nll:1941.617811\n",
      "iter:42, delta_VLB:28.129907, negVLB:8301.449815, err:0.107624, nll:1940.710238\n",
      "iter:43, delta_VLB:26.181061, negVLB:8275.268754, err:0.105912, nll:1939.582985\n",
      "iter:44, delta_VLB:27.889051, negVLB:8247.379703, err:0.105524, nll:1937.791347\n",
      "iter:45, delta_VLB:33.472905, negVLB:8213.906797, err:0.104356, nll:1935.126611\n",
      "iter:46, delta_VLB:36.698093, negVLB:8177.208704, err:0.100759, nll:1931.818635\n",
      "iter:47, delta_VLB:36.565464, negVLB:8140.643240, err:0.097310, nll:1928.268133\n",
      "iter:48, delta_VLB:33.935495, negVLB:8106.707745, err:0.091672, nll:1924.798734\n",
      "iter:49, delta_VLB:29.983276, negVLB:8076.724468, err:0.083531, nll:1921.615292\n",
      "iter:50, delta_VLB:26.036416, negVLB:8050.688052, err:0.078136, nll:1918.799214\n",
      "iter:51, delta_VLB:22.719037, negVLB:8027.969016, err:0.073513, nll:1916.367450\n",
      "iter:52, delta_VLB:18.603167, negVLB:8009.365848, err:0.069280, nll:1914.392509\n",
      "iter:53, delta_VLB:14.280975, negVLB:7995.084874, err:0.067073, nll:1912.946113\n",
      "iter:54, delta_VLB:10.744196, negVLB:7984.340677, err:0.066316, nll:1912.011324\n",
      "iter:55, delta_VLB:7.937329, negVLB:7976.403349, err:0.065355, nll:1911.511137\n",
      "iter:56, delta_VLB:5.204079, negVLB:7971.199270, err:0.064517, nll:1911.341274\n",
      "iter:57, delta_VLB:3.497638, negVLB:7967.701633, err:0.064748, nll:1911.361812\n",
      "iter:58, delta_VLB:2.847742, negVLB:7964.853890, err:0.064657, nll:1911.445529\n",
      "iter:59, delta_VLB:2.802319, negVLB:7962.051571, err:0.065769, nll:1911.509350\n",
      "iter:60, delta_VLB:3.348125, negVLB:7958.703446, err:0.065389, nll:1911.482719\n",
      "iter:61, delta_VLB:4.096237, negVLB:7954.607209, err:0.064668, nll:1911.327162\n",
      "iter:62, delta_VLB:4.368537, negVLB:7950.238672, err:0.064821, nll:1911.047194\n",
      "iter:63, delta_VLB:4.520173, negVLB:7945.718499, err:0.065479, nll:1910.661156\n",
      "iter:64, delta_VLB:4.645989, negVLB:7941.072510, err:0.066584, nll:1910.199249\n",
      "iter:65, delta_VLB:4.552957, negVLB:7936.519553, err:0.066372, nll:1909.691089\n",
      "iter:66, delta_VLB:4.300093, negVLB:7932.219461, err:0.065059, nll:1909.149379\n",
      "iter:67, delta_VLB:4.012287, negVLB:7928.207174, err:0.065034, nll:1908.584870\n",
      "iter:68, delta_VLB:3.611329, negVLB:7924.595845, err:0.064208, nll:1908.022560\n",
      "iter:69, delta_VLB:3.031169, negVLB:7921.564676, err:0.063742, nll:1907.483263\n",
      "iter:70, delta_VLB:2.462082, negVLB:7919.102594, err:0.064257, nll:1906.965321\n",
      "iter:71, delta_VLB:1.990600, negVLB:7917.111994, err:0.065193, nll:1906.458521\n",
      "iter:72, delta_VLB:1.599355, negVLB:7915.512639, err:0.065509, nll:1905.961264\n",
      "iter:73, delta_VLB:1.226882, negVLB:7914.285756, err:0.066128, nll:1905.488337\n",
      "iter:74, delta_VLB:0.880288, negVLB:7913.405468, err:0.065461, nll:1905.061899\n",
      "iter:75, delta_VLB:0.650973, negVLB:7912.754494, err:0.065518, nll:1904.694487\n",
      "iter:76, delta_VLB:0.476142, negVLB:7912.278352, err:0.064723, nll:1904.385201\n",
      "iter:77, delta_VLB:0.379666, negVLB:7911.898686, err:0.065081, nll:1904.118375\n",
      "iter:78, delta_VLB:0.443684, negVLB:7911.455002, err:0.065223, nll:1903.876134\n",
      "iter:79, delta_VLB:0.545507, negVLB:7910.909495, err:0.064917, nll:1903.660226\n",
      "iter:80, delta_VLB:0.582672, negVLB:7910.326823, err:0.065238, nll:1903.488660\n",
      "iter:81, delta_VLB:0.579453, negVLB:7909.747371, err:0.065430, nll:1903.374353\n",
      "iter:82, delta_VLB:0.608627, negVLB:7909.138743, err:0.066192, nll:1903.316106\n",
      "iter:83, delta_VLB:0.636593, negVLB:7908.502150, err:0.066005, nll:1903.308425\n",
      "iter:84, delta_VLB:0.609783, negVLB:7907.892367, err:0.066149, nll:1903.345194\n",
      "iter:85, delta_VLB:0.545309, negVLB:7907.347059, err:0.066149, nll:1903.417641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:86, delta_VLB:0.467833, negVLB:7906.879226, err:0.066177, nll:1903.516518\n",
      "iter:87, delta_VLB:0.390212, negVLB:7906.489013, err:0.066862, nll:1903.631981\n",
      "iter:88, delta_VLB:0.297618, negVLB:7906.191395, err:0.066669, nll:1903.755592\n",
      "iter:89, delta_VLB:0.211458, negVLB:7905.979937, err:0.066466, nll:1903.881206\n",
      "iter:90, delta_VLB:0.166361, negVLB:7905.813575, err:0.066623, nll:1904.003330\n",
      "iter:91, delta_VLB:0.134862, negVLB:7905.678714, err:0.066156, nll:1904.116694\n",
      "iter:92, delta_VLB:0.112795, negVLB:7905.565918, err:0.066324, nll:1904.213661\n",
      "iter:93, delta_VLB:0.112350, negVLB:7905.453568, err:0.065885, nll:1904.285710\n",
      "iter:94, delta_VLB:0.113677, negVLB:7905.339891, err:0.065483, nll:1904.328876\n",
      "iter:95, delta_VLB:0.107278, negVLB:7905.232612, err:0.065106, nll:1904.344928\n",
      "iter:96, delta_VLB:0.108595, negVLB:7905.124018, err:0.064503, nll:1904.338353\n",
      "iter:97, delta_VLB:0.118589, negVLB:7905.005429, err:0.064364, nll:1904.314111\n",
      "iter:98, delta_VLB:0.118749, negVLB:7904.886679, err:0.063650, nll:1904.277117\n",
      "iter:99, delta_VLB:0.108904, negVLB:7904.777775, err:0.063655, nll:1904.231542\n",
      "iter:100, delta_VLB:0.100790, negVLB:7904.676985, err:0.063305, nll:1904.181458\n",
      "iter:101, delta_VLB:0.095713, negVLB:7904.581272, err:0.063827, nll:1904.131513\n",
      "iter:102, delta_VLB:0.083313, negVLB:7904.497960, err:0.063378, nll:1904.086144\n",
      "iter:103, delta_VLB:0.066967, negVLB:7904.430992, err:0.063474, nll:1904.047084\n",
      "iter:104, delta_VLB:0.059053, negVLB:7904.371939, err:0.063850, nll:1904.012678\n",
      "iter:105, delta_VLB:0.050937, negVLB:7904.321002, err:0.064283, nll:1903.981124\n",
      "iter:106, delta_VLB:0.037234, negVLB:7904.283769, err:0.064905, nll:1903.952486\n",
      "iter:107, delta_VLB:0.024974, negVLB:7904.258795, err:0.064839, nll:1903.928252\n",
      "iter:108, delta_VLB:0.018232, negVLB:7904.240563, err:0.064905, nll:1903.909822\n",
      "iter:109, delta_VLB:0.017346, negVLB:7904.223217, err:0.065140, nll:1903.897029\n",
      "iter:110, delta_VLB:0.019627, negVLB:7904.203591, err:0.065193, nll:1903.888118\n",
      "iter:111, delta_VLB:0.021747, negVLB:7904.181844, err:0.065271, nll:1903.880735\n",
      "iter:112, delta_VLB:0.025287, negVLB:7904.156556, err:0.065403, nll:1903.872598\n",
      "iter:113, delta_VLB:0.029569, negVLB:7904.126987, err:0.065656, nll:1903.862583\n",
      "iter:114, delta_VLB:0.030274, negVLB:7904.096714, err:0.065469, nll:1903.851582\n",
      "iter:115, delta_VLB:0.026976, negVLB:7904.069737, err:0.065461, nll:1903.841755\n",
      "iter:116, delta_VLB:0.021719, negVLB:7904.048018, err:0.065500, nll:1903.835011\n",
      "iter:117, delta_VLB:0.016463, negVLB:7904.031555, err:0.065517, nll:1903.831794\n",
      "iter:118, delta_VLB:0.012033, negVLB:7904.019522, err:0.065610, nll:1903.831442\n",
      "iter:119, delta_VLB:0.008561, negVLB:7904.010961, err:0.065471, nll:1903.833709\n",
      "iter:120, delta_VLB:0.006224, negVLB:7904.004737, err:0.065315, nll:1903.839418\n",
      "iter:121, delta_VLB:0.005454, negVLB:7903.999283, err:0.065190, nll:1903.849493\n",
      "iter:122, delta_VLB:0.005598, negVLB:7903.993685, err:0.064948, nll:1903.863640\n",
      "iter:123, delta_VLB:0.005601, negVLB:7903.988084, err:0.064948, nll:1903.880060\n",
      "iter:124, delta_VLB:0.005529, negVLB:7903.982555, err:0.065043, nll:1903.896323\n",
      "iter:125, delta_VLB:0.005976, negVLB:7903.976579, err:0.064894, nll:1903.910460\n",
      "iter:126, delta_VLB:0.006181, negVLB:7903.970398, err:0.064894, nll:1903.921672\n",
      "iter:127, delta_VLB:0.005715, negVLB:7903.964684, err:0.064894, nll:1903.930307\n",
      "iter:128, delta_VLB:0.005624, negVLB:7903.959060, err:0.064894, nll:1903.936931\n",
      "iter:129, delta_VLB:0.005286, negVLB:7903.953773, err:0.064894, nll:1903.941363\n",
      "iter:130, delta_VLB:0.004360, negVLB:7903.949413, err:0.064894, nll:1903.942685\n",
      "iter:131, delta_VLB:0.003778, negVLB:7903.945635, err:0.064790, nll:1903.940281\n",
      "iter:132, delta_VLB:0.003563, negVLB:7903.942073, err:0.064790, nll:1903.934647\n",
      "iter:133, delta_VLB:0.003189, negVLB:7903.938884, err:0.064818, nll:1903.926812\n",
      "iter:134, delta_VLB:0.002683, negVLB:7903.936201, err:0.064975, nll:1903.917347\n",
      "iter:135, delta_VLB:0.002120, negVLB:7903.934081, err:0.064975, nll:1903.906504\n",
      "iter:136, delta_VLB:0.001549, negVLB:7903.932532, err:0.064897, nll:1903.894922\n",
      "iter:137, delta_VLB:0.001202, negVLB:7903.931331, err:0.064897, nll:1903.883680\n",
      "iter:138, delta_VLB:0.000888, negVLB:7903.930442, err:0.065004, nll:1903.873812\n",
      "iter:139, delta_VLB:0.000730, negVLB:7903.929713, err:0.065118, nll:1903.866091\n",
      "iter:140, delta_VLB:0.000862, negVLB:7903.928850, err:0.065118, nll:1903.861118\n",
      "iter:141, delta_VLB:0.001007, negVLB:7903.927843, err:0.065274, nll:1903.859082\n",
      "iter:142, delta_VLB:0.001170, negVLB:7903.926673, err:0.065118, nll:1903.859458\n",
      "iter:143, delta_VLB:0.001319, negVLB:7903.925354, err:0.065191, nll:1903.861428\n",
      "iter:144, delta_VLB:0.001331, negVLB:7903.924023, err:0.065191, nll:1903.864548\n",
      "iter:145, delta_VLB:0.001245, negVLB:7903.922778, err:0.064785, nll:1903.868654\n",
      "iter:146, delta_VLB:0.001015, negVLB:7903.921763, err:0.064899, nll:1903.873330\n",
      "iter:147, delta_VLB:0.000787, negVLB:7903.920976, err:0.064899, nll:1903.877945\n",
      "iter:148, delta_VLB:0.000584, negVLB:7903.920392, err:0.064646, nll:1903.882158\n",
      "iter:149, delta_VLB:0.000384, negVLB:7903.920008, err:0.064651, nll:1903.885922\n",
      "iter:150, delta_VLB:0.000288, negVLB:7903.919720, err:0.064651, nll:1903.888979\n",
      "iter:151, delta_VLB:0.000251, negVLB:7903.919469, err:0.064693, nll:1903.890824\n",
      "iter:152, delta_VLB:0.000215, negVLB:7903.919254, err:0.064693, nll:1903.891302\n",
      "iter:153, delta_VLB:0.000222, negVLB:7903.919032, err:0.064693, nll:1903.890891\n",
      "iter:154, delta_VLB:0.000263, negVLB:7903.918769, err:0.064693, nll:1903.890196\n",
      "iter:155, delta_VLB:0.000267, negVLB:7903.918502, err:0.064693, nll:1903.889417\n",
      "iter:156, delta_VLB:0.000259, negVLB:7903.918243, err:0.064693, nll:1903.888469\n",
      "iter:157, delta_VLB:0.000270, negVLB:7903.917973, err:0.064693, nll:1903.887448\n",
      "iter:158, delta_VLB:0.000260, negVLB:7903.917713, err:0.064818, nll:1903.886676\n",
      "iter:159, delta_VLB:0.000242, negVLB:7903.917471, err:0.064818, nll:1903.886351\n",
      "iter:160, delta_VLB:0.000227, negVLB:7903.917243, err:0.064818, nll:1903.886369\n",
      "iter:161, delta_VLB:0.000190, negVLB:7903.917054, err:0.064818, nll:1903.886555\n",
      "iter:162, delta_VLB:0.000154, negVLB:7903.916900, err:0.064818, nll:1903.886878\n",
      "iter:163, delta_VLB:0.000127, negVLB:7903.916772, err:0.064818, nll:1903.887370\n",
      "iter:164, delta_VLB:0.000106, negVLB:7903.916666, err:0.064818, nll:1903.887944\n",
      "iter:165, delta_VLB:0.000084, negVLB:7903.916582, err:0.064740, nll:1903.888422\n",
      "iter:166, delta_VLB:0.000055, negVLB:7903.916527, err:0.064615, nll:1903.888696\n",
      "iter:167, delta_VLB:0.000046, negVLB:7903.916481, err:0.064772, nll:1903.888752\n",
      "iter:168, delta_VLB:0.000047, negVLB:7903.916434, err:0.064772, nll:1903.888560\n",
      "iter:169, delta_VLB:0.000050, negVLB:7903.916384, err:0.064885, nll:1903.888057\n",
      "iter:170, delta_VLB:0.000050, negVLB:7903.916333, err:0.064885, nll:1903.887256\n",
      "iter:171, delta_VLB:0.000057, negVLB:7903.916277, err:0.064772, nll:1903.886291\n",
      "iter:172, delta_VLB:0.000059, negVLB:7903.916217, err:0.064772, nll:1903.885330\n",
      "iter:173, delta_VLB:0.000056, negVLB:7903.916161, err:0.064850, nll:1903.884514\n",
      "iter:174, delta_VLB:0.000052, negVLB:7903.916109, err:0.064850, nll:1903.883987\n",
      "iter:175, delta_VLB:0.000043, negVLB:7903.916065, err:0.064850, nll:1903.883852\n",
      "iter:176, delta_VLB:0.000039, negVLB:7903.916027, err:0.064850, nll:1903.884054\n",
      "iter:177, delta_VLB:0.000032, negVLB:7903.915994, err:0.064850, nll:1903.884418\n",
      "iter:178, delta_VLB:0.000026, negVLB:7903.915968, err:0.064850, nll:1903.884865\n",
      "iter:179, delta_VLB:0.000022, negVLB:7903.915946, err:0.064850, nll:1903.885462\n",
      "iter:180, delta_VLB:0.000015, negVLB:7903.915931, err:0.064850, nll:1903.886223\n",
      "iter:181, delta_VLB:0.000013, negVLB:7903.915919, err:0.064693, nll:1903.886992\n",
      "iter:182, delta_VLB:0.000012, negVLB:7903.915907, err:0.064693, nll:1903.887592\n",
      "iter:183, delta_VLB:0.000009, negVLB:7903.915898, err:0.064693, nll:1903.887972\n",
      "iter:184, delta_VLB:0.000008, negVLB:7903.915890, err:0.064693, nll:1903.888131\n",
      "iter:185, delta_VLB:0.000012, negVLB:7903.915878, err:0.064693, nll:1903.888051\n",
      "iter:186, delta_VLB:0.000014, negVLB:7903.915865, err:0.064693, nll:1903.887738\n",
      "iter:187, delta_VLB:0.000015, negVLB:7903.915850, err:0.064693, nll:1903.887236\n",
      "iter:188, delta_VLB:0.000014, negVLB:7903.915835, err:0.064693, nll:1903.886588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:189, delta_VLB:0.000012, negVLB:7903.915823, err:0.064693, nll:1903.885873\n",
      "iter:190, delta_VLB:0.000010, negVLB:7903.915813, err:0.064693, nll:1903.885223\n",
      "iter:191, delta_VLB:0.000007, negVLB:7903.915806, err:0.064693, nll:1903.884737\n",
      "iter:192, delta_VLB:0.000005, negVLB:7903.915801, err:0.064693, nll:1903.884412\n",
      "iter:193, delta_VLB:0.000003, negVLB:7903.915798, err:0.064693, nll:1903.884238\n",
      "iter:194, delta_VLB:0.000002, negVLB:7903.915796, err:0.064693, nll:1903.884254\n",
      "iter:195, delta_VLB:0.000002, negVLB:7903.915793, err:0.064693, nll:1903.884477\n",
      "iter:196, delta_VLB:0.000003, negVLB:7903.915790, err:0.064693, nll:1903.884852\n",
      "iter:197, delta_VLB:0.000003, negVLB:7903.915787, err:0.064693, nll:1903.885311\n",
      "iter:198, delta_VLB:0.000004, negVLB:7903.915783, err:0.064693, nll:1903.885827\n",
      "iter:199, delta_VLB:0.000004, negVLB:7903.915780, err:0.064850, nll:1903.886364\n",
      "iter:200, delta_VLB:0.000003, negVLB:7903.915777, err:0.064850, nll:1903.886843\n",
      "iter:201, delta_VLB:0.000003, negVLB:7903.915774, err:0.064850, nll:1903.887182\n",
      "iter:202, delta_VLB:0.000003, negVLB:7903.915771, err:0.064850, nll:1903.887349\n",
      "iter:203, delta_VLB:0.000003, negVLB:7903.915768, err:0.064850, nll:1903.887365\n",
      "iter:204, delta_VLB:0.000002, negVLB:7903.915766, err:0.064850, nll:1903.887273\n",
      "iter:205, delta_VLB:0.000002, negVLB:7903.915765, err:0.064850, nll:1903.887100\n",
      "iter:206, delta_VLB:0.000001, negVLB:7903.915764, err:0.064850, nll:1903.886849\n",
      "iter:207, delta_VLB:0.000001, negVLB:7903.915763, err:0.064850, nll:1903.886521\n",
      "iter:208, delta_VLB:0.000001, negVLB:7903.915762, err:0.064693, nll:1903.886152\n",
      "iter:209, delta_VLB:0.000001, negVLB:7903.915762, err:0.064693, nll:1903.885811\n",
      "iter:210, delta_VLB:0.000001, negVLB:7903.915761, err:0.064693, nll:1903.885567\n",
      "iter:211, delta_VLB:0.000001, negVLB:7903.915760, err:0.064693, nll:1903.885436\n",
      "iter:212, delta_VLB:0.000001, negVLB:7903.915759, err:0.064693, nll:1903.885394\n",
      "iter:213, delta_VLB:0.000001, negVLB:7903.915758, err:0.064693, nll:1903.885414\n",
      "iter:214, delta_VLB:0.000001, negVLB:7903.915757, err:0.064693, nll:1903.885497\n",
      "iter:215, delta_VLB:0.000001, negVLB:7903.915757, err:0.064693, nll:1903.885641\n",
      "iter:216, delta_VLB:0.000001, negVLB:7903.915756, err:0.064693, nll:1903.885823\n",
      "iter:217, delta_VLB:0.000000, negVLB:7903.915756, err:0.064693, nll:1903.886004\n",
      "iter:218, delta_VLB:0.000000, negVLB:7903.915755, err:0.064693, nll:1903.886161\n",
      "iter:219, delta_VLB:0.000000, negVLB:7903.915755, err:0.064693, nll:1903.886281\n",
      "iter:220, delta_VLB:0.000000, negVLB:7903.915755, err:0.064693, nll:1903.886353\n",
      "iter:221, delta_VLB:0.000000, negVLB:7903.915755, err:0.064693, nll:1903.886377\n",
      "iter:222, delta_VLB:0.000000, negVLB:7903.915755, err:0.064693, nll:1903.886361\n",
      "iter:223, delta_VLB:0.000000, negVLB:7903.915754, err:0.064693, nll:1903.886314\n",
      "iter:224, delta_VLB:0.000000, negVLB:7903.915754, err:0.064693, nll:1903.886247\n",
      "iter:225, delta_VLB:0.000000, negVLB:7903.915754, err:0.064693, nll:1903.886175\n",
      "iter:226, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.886104\n",
      "iter:227, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.886036\n",
      "iter:228, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.885983\n",
      "iter:229, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.885963\n",
      "iter:230, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.885977\n",
      "iter:231, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.886012\n",
      "iter:232, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.886053\n",
      "iter:233, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.886093\n",
      "iter:234, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.886130\n",
      "iter:235, delta_VLB:0.000000, negVLB:7903.915753, err:0.064693, nll:1903.886160\n",
      "iter:236, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886179\n",
      "iter:237, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886180\n",
      "iter:238, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886163\n",
      "iter:239, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886137\n",
      "iter:240, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886105\n",
      "iter:241, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886066\n",
      "iter:242, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886024\n",
      "iter:243, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.885990\n",
      "iter:244, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.885972\n",
      "iter:245, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.885968\n",
      "iter:246, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.885975\n",
      "iter:247, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.885991\n",
      "iter:248, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886014\n",
      "iter:249, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886042\n",
      "iter:250, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886070\n",
      "iter:251, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886094\n",
      "iter:252, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886114\n",
      "iter:253, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886128\n",
      "iter:254, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886136\n",
      "iter:255, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886137\n",
      "iter:256, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886133\n",
      "iter:257, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886125\n",
      "iter:258, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886116\n",
      "iter:259, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886105\n",
      "iter:260, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886096\n",
      "iter:261, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886090\n",
      "iter:262, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886085\n",
      "iter:263, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886083\n",
      "iter:264, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886083\n",
      "iter:265, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886085\n",
      "iter:266, delta_VLB:0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886086\n",
      "iter:267, delta_VLB:-0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886084\n",
      "iter:268, delta_VLB:-0.000000, negVLB:7903.915752, err:0.064693, nll:1903.886081\n",
      "After 268 iterations it converged: delta_VLB:0.000000, negVLB:7903.915752, err:0.064693\n"
     ]
    }
   ],
   "source": [
    "k='Matern52';lik='Poisson2';lr=1*10**0#0.5*10**-2;HMCSSVI\n",
    "# FPimSDm = Train(X_train,y_train,ix,X_test,y_test,max_iter=300,lr=lr,VLB_opt='MCSSVI',lik=lik,K=k)#Gaussian,Bernoulli,Poisson2,SDSVI\n",
    "# Zs,Zs_label, VLBSDm, length_scale, sigma2, m, V,noise_var, Kmm, Kmm_inv,A,VLB_timeSDm,errSDm,nllSDm=FPimSDm#Matern52,SE,Matern32\n",
    "FPimSD = Train(X_train,y_train,ix,X_test,y_test,max_iter=300,lr=lr,VLB_opt='SDSVI',lik=lik,K=k)#Gaussian,Bernoulli,Poisson2,SDSVI\n",
    "Zs,Zs_label, VLBSD, length_scale, sigma2, m, V,noise_var, Kmm, Kmm_inv,A,VLB_timeSD,errSD,nllSD=FPimSD#Matern52,SE,Matern32\n",
    "FPim1 = Train(X_train,y_train,ix,X_test,y_test,max_iter=300,lr=lr,VLB_opt='GD',lik=lik,K=k)#Gaussian,Bernoulli,Poisson2,SDSVI\n",
    "Zs,Zs_label, VLB1, length_scale, sigma2, m, V,noise_var, Kmm, Kmm_inv,A,VLB_time1,err1,nll1=FPim1#Matern52,SE,Matern32\n",
    "# FPim2 = Train(X_train,y_train,ix,X_test,y_test,max_iter=300,lr=lr,VLB_opt='FPb',lik=lik,K=k)#Gaussian,Bernoulli\n",
    "# Zs,Zs_label, VLB2, length_scale, sigma2, m, V,noise_var, Kmm, Kmm_inv,A,VLB_time2,err2,nll2=FPim2#Matern52,SE\n",
    "# FPim3 = Train(X_train,y_train,ix,X_test,y_test,max_iter=300,lr=lr,VLB_opt='FPi',lik=lik,K=k)#Gaussian,Bernoulli\n",
    "# Zs,Zs_label, VLB3, length_scale, sigma2, m, V,noise_var, Kmm, Kmm_inv,A,VLB_time3,err3,nll3=FPim3#Matern32,SE\n",
    "# FPim4 = Train(X_train,y_train,ix,X_test,y_test,max_iter=300,lr=lr,VLB_opt='FPi-mean',lik=lik,K=k)#Gaussian,Bernoulli\n",
    "# Zs,Zs_label, VLB4, length_scale, sigma2, m, V,noise_var, Kmm, Kmm_inv,A,VLB_time4,err4,nll4=FPim4#Matern32,SE\n",
    "# FPH = Train(X_train,y_train,ix,X_test,y_test,max_iter=300,lr=lr,VLB_opt='HMCSSVI',lik=lik,K=k)#Gaussian,Bernoulli,Poisson2,SDSVI\n",
    "# Zs,Zs_label, VLBH, length_scale, sigma2, m, V,noise_var, Kmm, Kmm_inv,A,VLB_timeH,errH,nllH=FPH#Matern52,SE,Matern32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.pyplot as plt\n",
    "host = host_subplot(111)\n",
    "par = host.twinx()\n",
    "host.set_xlabel(\"Training time(log)\")\n",
    "host.set_ylabel(\"negVLB\");\n",
    "# par.set_ylabel(\"err\")\n",
    "# p0, = host.plot(VLB_time1, VLB1, 'bo-', lw=1, markersize=5, label=\"negVLB GD\")\n",
    "# p1, = host.plot(VLB_timeSD, VLBSD, 'ro-', lw=1, markersize=5, label=\"negVLB S-DSVI\")\n",
    "# p2, = par.plot(VLB_time1, err1, 'bs--', lw=1, markersize=5,fillstyle='none', label=\"err GD\")\n",
    "# p3, = par.plot(VLB_timeSD, errSD, 'rs--', lw=1, markersize=5,fillstyle='none', label=\"err S-DSVI\")\n",
    "par.set_ylabel(\"nll\")\n",
    "p0, = host.plot(VLB_time1, VLB1, 'bo-', lw=1, markersize=5, label=\"negVLB GD\")\n",
    "p1, = host.plot(VLB_timeSD, VLBSD, 'ro-', lw=1, markersize=5, label=\"negVLB S-DSVI\")\n",
    "p2, = par.plot(VLB_time1, nll1, 'bs--', lw=1, markersize=5,fillstyle='none', label=\"nll GD\")\n",
    "p3, = par.plot(VLB_timeSD, nllSD, 'rs--', lw=1, markersize=5,fillstyle='none', label=\"nll S-DSVI\")\n",
    "# p2, = par.plot(VLB_time1, nll1, 'bs--', lw=1, markersize=5,fillstyle='none', label=\"nll GD\")\n",
    "# p3, = par.plot(VLB_timeSD, nllSD, 'rs--', lw=1, markersize=5,fillstyle='none', label=\"nll S-DSVI\")\n",
    "# p2, = par.plot(VLB_time1, err1, 'bs--', lw=1, markersize=5,fillstyle='none', label=\"err GD\")\n",
    "# p3, = par.plot(VLB_timeSD, errSD, 'rs--', lw=1, markersize=5,fillstyle='none', label=\"err S-DSVI\")\n",
    "# p5, = par.plot(VLB_timeSD1, nllSD1, 'gs--', lw=1, markersize=5,fillstyle='none', label=\"nll SDSVI1\")\n",
    "\n",
    "host.set_xscale('log',basex=10)\n",
    "leg = plt.legend()\n",
    "host.yaxis.get_label().set_color(p0.get_color());par.yaxis.get_label().set_color(p2.get_color())\n",
    "leg.texts[0].set_color(p0.get_color());\n",
    "leg.texts[1].set_color(p1.get_color())\n",
    "leg.texts[2].set_color(p2.get_color());\n",
    "leg.texts[3].set_color(p3.get_color())\n",
    "# leg.texts[4].set_color(p4.get_color());\n",
    "# leg.texts[5].set_color(p5.get_color())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = host_subplot(111)\n",
    "par = host.twinx()\n",
    "host.set_xlabel(\"Training time(log)\")\n",
    "host.set_ylabel(\"nll\");\n",
    "p0, = host.plot(VLB_timeSD, nllSD, 'bo-', lw=1, markersize=5, label=\"S-DSVI\")\n",
    "p1, = host.plot(VLB_timeH, nllH, 'go-', lw=1, markersize=5, label=\"H-MC-SSVI\")\n",
    "p2, = host.plot(VLB_timeSDm, nllSDm, 'ro-', lw=1, markersize=5, label=\"MC-SSVI\")\n",
    "# host.set_ylabel(\"err\")\n",
    "# p0, = host.plot(VLB_timeSD, errSD, 'bo-', lw=1, markersize=5, label=\"S-DSVI\")\n",
    "# p1, = host.plot(VLB_timeH, errH, 'go-', lw=1, markersize=5, label=\"H-MC-SSVI\")\n",
    "# p2, = host.plot(VLB_timeSDm, errSDm, 'ro-', lw=1, markersize=5, label=\"MC-SSVI\")\n",
    "# p2, = par.plot(VLB_time1, nll1, 'bs--', lw=1, markersize=5,fillstyle='none', label=\"nll GD\")\n",
    "# p3, = par.plot(VLB_timeSD, nllSD, 'rs--', lw=1, markersize=5,fillstyle='none', label=\"nll SD-SVI\")\n",
    "# p2, = par.plot(VLB_time1, err1, 'bs--', lw=1, markersize=5,fillstyle='none', label=\"err GD\")\n",
    "# p3, = par.plot(VLB_timeSD, errSD, 'rs--', lw=1, markersize=5,fillstyle='none', label=\"nll SD-SVI\")\n",
    "# p5, = par.plot(VLB_timeSD1, nllSD1, 'gs--', lw=1, markersize=5,fillstyle='none', label=\"nll SDSVI1\")\n",
    "\n",
    "host.set_xscale('log',basex=10)\n",
    "leg = plt.legend()\n",
    "host.yaxis.get_label().set_color(p0.get_color());#par.yaxis.get_label().set_color(p2.get_color())\n",
    "leg.texts[0].set_color(p0.get_color());\n",
    "leg.texts[1].set_color(p1.get_color())\n",
    "leg.texts[2].set_color(p2.get_color());\n",
    "# leg.texts[3].set_color(p3.get_color())\n",
    "# leg.texts[4].set_color(p4.get_color());\n",
    "# leg.texts[5].set_color(p5.get_color())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.pyplot as plt\n",
    "host = host_subplot(111)\n",
    "par = host.twinx()\n",
    "host.set_xlabel(\"Training time(log)\")\n",
    "host.set_ylabel(\"negVLB\");\n",
    "# par.set_ylabel(\"ERR\")\n",
    "par.set_ylabel(\"NLL\")\n",
    "\n",
    "p0, = host.plot(VLB_time1, VLB1, 'bo-', lw=1, markersize=5, label=\"negVLB GD\")\n",
    "p1, = host.plot(VLB_timeSD, VLBSD, 'ro-', lw=1, markersize=5, label=\"negVLB SDSVI\")\n",
    "# p2, = host.plot(VLB_timeSD1, VLBSD1, 'go-', lw=1, markersize=5, label=\"negVLB SDSVI1\")\n",
    "p2, = par.plot(VLB_time1, nll1, 'bs--', lw=1, markersize=5,fillstyle='none', label=\"nll GD\")\n",
    "p3, = par.plot(VLB_timeSD, nllSD, 'rs--', lw=1, markersize=5,fillstyle='none', label=\"nll SDSVI\")\n",
    "# p2, = par.plot(VLB_time1, err1, 'bs--', lw=1, markersize=5,fillstyle='none', label=\"nll GD\")\n",
    "# p3, = par.plot(VLB_timeSD, errSD, 'rs--', lw=1, markersize=5,fillstyle='none', label=\"nll SDSVI\")\n",
    "# p5, = par.plot(VLB_timeSD1, nllSD1, 'gs--', lw=1, markersize=5,fillstyle='none', label=\"nll SDSVI1\")\n",
    "\n",
    "host.set_xscale('log',basex=10)\n",
    "leg = plt.legend()\n",
    "host.yaxis.get_label().set_color(p0.get_color());par.yaxis.get_label().set_color(p2.get_color())\n",
    "leg.texts[0].set_color(p0.get_color());\n",
    "leg.texts[1].set_color(p1.get_color())\n",
    "leg.texts[2].set_color(p2.get_color());\n",
    "leg.texts[3].set_color(p3.get_color())\n",
    "# leg.texts[4].set_color(p4.get_color());\n",
    "# leg.texts[5].set_color(p5.get_color())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "VLB1 = (VLB1-min(VLB1))/(max(VLB1)-min(VLB1)); nll1 = (nll1-min(nll1))/(max(nll1)-min(nll1))\n",
    "VLB2 = (VLB2-min(VLB2))/(max(VLB2)-min(VLB2)); nll2 = (nll2-min(nll2))/(max(nll2)-min(nll2))\n",
    "VLB3 = (VLB3-min(VLB3))/(max(VLB3)-min(VLB3)); nll3 = (nll3-min(nll3))/(max(nll3)-min(nll3))\n",
    "VLB4 = (VLB4-min(VLB4))/(max(VLB4)-min(VLB4)); nll4 = (nll4-min(nll4))/(max(nll4)-min(nll4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.pyplot as plt\n",
    "host = host_subplot(111)\n",
    "# par = host.twinx()\n",
    "host.set_xlabel(\"Training time(log)\")\n",
    "host.set_ylabel(\"negVLB\")\n",
    "\n",
    "p0, = host.plot(VLB_time1, VLB1, 'bo-', lw=1, markersize=5, label=\"negVLB GD\")\n",
    "p1, = host.plot(VLB_time2, VLB2, 'ro-', lw=1, markersize=5, label=\"negVLB FPb\")\n",
    "p2, = host.plot(VLB_time3, VLB3, 'go-', lw=1, markersize=5, label=\"negVLB FPi\")\n",
    "p3, = host.plot(VLB_time4, VLB4, 'co-', lw=1, markersize=5, label=\"negVLB FPi-mean\")\n",
    "\n",
    "host.set_xscale('log',basex=10)\n",
    "leg = plt.legend()\n",
    "host.yaxis.get_label().set_color(p0.get_color());#par.yaxis.get_label().set_color(p0.get_color())\n",
    "leg.texts[0].set_color(p0.get_color());\n",
    "leg.texts[1].set_color(p1.get_color())\n",
    "leg.texts[2].set_color(p2.get_color());\n",
    "leg.texts[3].set_color(p3.get_color())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.pyplot as plt\n",
    "host = host_subplot(111)\n",
    "par = host.twinx()\n",
    "host.set_xlabel(\"Training time(log)\")\n",
    "host.set_ylabel(\"Error\")\n",
    "par.set_ylabel(\"NLL\")#negVLB\n",
    "p0, = host.plot(VLB_time1, err1, 'bo--', lw=1, markersize=5, fillstyle='none', label=\"error GD\")\n",
    "p1, = host.plot(VLB_time2, err2, 'ro--', lw=1, markersize=5, fillstyle='none', label=\"error FPb\")\n",
    "p2, = host.plot(VLB_time3, err3, 'go--', lw=1, markersize=5, fillstyle='none', label=\"error FPi\")\n",
    "p3, = host.plot(VLB_time4, err4, 'co--', markersize=5, lw=1, fillstyle='none', label=\"error FPi-mean\")\n",
    "p4, = par.plot(VLB_time1, nll1, 'bs-', lw=1, markersize=5, label=\"nll GD\")\n",
    "p5, = par.plot(VLB_time2, nll2, 'rs-', lw=1, markersize=5, label=\"nll FPb\")\n",
    "p6, = par.plot(VLB_time3, nll3, 'gs-', lw=1, markersize=5, label=\"nll FPi\")\n",
    "p7, = par.plot(VLB_time4, nll4, 'cs-', lw=1, markersize=5, label=\"nll FPi-mean\")\n",
    "# p8, = par.plot(VLB_time1, VLB1, 'bo-', lw=1, markersize=5, label=\"negVLB GD\")\n",
    "# p9, = par.plot(VLB_time2, VLB2, 'ro-', lw=1, markersize=5, label=\"negVLB FPb\")\n",
    "# p10, = par.plot(VLB_time3, VLB3, 'go-', lw=1, markersize=5, label=\"negVLB FPi\")\n",
    "# p11, = par.plot(VLB_time4, VLB4, 'c+-', lw=1, markersize=5, label=\"negVLB FPi-mean\")\n",
    "\n",
    "host.set_xscale('log',basex=10)\n",
    "leg = plt.legend()\n",
    "host.yaxis.get_label().set_color(p0.get_color());par.yaxis.get_label().set_color(p0.get_color())\n",
    "leg.texts[0].set_color(p0.get_color());\n",
    "leg.texts[1].set_color(p1.get_color())\n",
    "leg.texts[2].set_color(p2.get_color());\n",
    "leg.texts[3].set_color(p3.get_color())\n",
    "leg.texts[4].set_color(p4.get_color());\n",
    "leg.texts[5].set_color(p5.get_color())\n",
    "leg.texts[6].set_color(p6.get_color());\n",
    "leg.texts[7].set_color(p7.get_color())\n",
    "# leg.texts[8].set_color(p8.get_color());\n",
    "# leg.texts[9].set_color(p9.get_color())\n",
    "# leg.texts[10].set_color(p10.get_color());\n",
    "# leg.texts[11].set_color(p11.get_color())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data(count regression) count_dataset_ucsdpeds1l_N4000_D30,count_dataset_abalone_N4177_D9,count_dataset_flares_N1065_D24\n",
    "mat_contents = sio.loadmat('count_dataset_ucsdpeds1l_N4000_D30.mat')#count_dataset_epid_N6238_D17,count_dataset_bikehour2011_N8734_D49\n",
    "x = mat_contents['x']; y = mat_contents['y'] #count_dataset_segment_N2310_D19;class_dataset_madelon_N2600_D500;class_dataset_usps35_N1540_D256\n",
    "x = x.astype('double')#class_dataset_musk_N6598_D166;class_dataset_yeast_N1484_D8,reg_dataset_mg_N1385_D6\n",
    "#reg_dataset_cpusmall_N8192_D12,reg_dataset_spacega_N3107_D6\n",
    "# shuffle the data and split data into training set and test set\n",
    "data = np.concatenate((x,y), axis=1)\n",
    "np.random.shuffle(data)\n",
    "num_data = data.shape[0]; dim_data = data.shape[1] - 1;\n",
    "num_train = int(0.8*np.ceil(num_data)); num_test = num_data - num_train\n",
    "x_train = data[:num_train, :-1]; y_train = data[:num_train, -1];\n",
    "x_test = data[num_train:, :-1]; y_test = data[num_train:, -1];\n",
    "y_train = y_train[:, None]; y_test = y_test[:, None]\n",
    "# data Standardization with zero mean and unit variance\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "X_train = scaler.transform(x_train); X_test = scaler.transform(x_test)\n",
    "np.random.seed(10);num_inducing=200\n",
    "ix = random.sample(range(num_train), num_inducing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.pyplot as plt\n",
    "host = host_subplot(111)\n",
    "par = host.twinx()\n",
    "host.set_xlabel(\"Training time(log)\")\n",
    "host.set_ylabel(\"Error\")\n",
    "par.set_ylabel(\"negVLB\")\n",
    "# p0, = host.plot(VLB_time, err, 'bo--', lw=1, markersize=5, fillstyle='none', label=\"Poisson GD error\")\n",
    "# p1, = host.plot(VLB_time2, err2, 'ro--', lw=1, markersize=5, fillstyle='none', label=\"Poisson2 GD error\")\n",
    "# p2, = par.plot(VLB_time, VLB, 'bo-', lw=1, markersize=5, label=\"Poisson GD negVLB\")\n",
    "# p3, = par.plot(VLB_time2, VLB2, 'ro-', lw=1, markersize=5, label=\"Poisson2 GD negVLB\")\n",
    "# p0, = host.plot(VLB_time_FPb, err_FPb, 'bo--', lw=1, markersize=5, fillstyle='none', label=\"Poisson FPb error\")\n",
    "# p1, = host.plot(VLB_time_FPb2, err_FPb2, 'ro--', lw=1, markersize=5, fillstyle='none', label=\"Poisson2 FPb error\")\n",
    "# p2, = par.plot(VLB_time_FPb, VLB_FPb, 'bo-', lw=1, markersize=5, label=\"Poisson FPb negVLB\")\n",
    "# p3, = par.plot(VLB_time_FPb2, VLB_FPb2, 'ro-', lw=1, markersize=5, label=\"Poisson2 FPb negVLB\")\n",
    "p0, = host.plot(VLB_time_FPi, err_FPi, 'bo--', lw=1, markersize=5, fillstyle='none', label=\"Poisson FPi error\")\n",
    "p1, = host.plot(VLB_time_FPi2, err_FPi2, 'ro--', lw=1, markersize=5, fillstyle='none', label=\"Poisson2 FPi error\")\n",
    "p2, = par.plot(VLB_time_FPi, VLB_FPi, 'bo-', lw=1, markersize=5, label=\"Poisson FPb negVLB\")\n",
    "p3, = par.plot(VLB_time_FPi2, VLB_FPi2, 'ro-', lw=1, markersize=5, label=\"Poisson2 FPb negVLB\")\n",
    "host.set_xscale('log',basex=10)\n",
    "leg = plt.legend()\n",
    "host.yaxis.get_label().set_color(p0.get_color());par.yaxis.get_label().set_color(p0.get_color())\n",
    "leg.texts[0].set_color(p0.get_color());\n",
    "leg.texts[1].set_color(p1.get_color())\n",
    "leg.texts[2].set_color(p2.get_color());\n",
    "leg.texts[3].set_color(p3.get_color())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.pyplot as plt\n",
    "host = host_subplot(111)\n",
    "par = host.twinx()\n",
    "host.set_xlabel(\"Training time(log)\")\n",
    "host.set_ylabel(\"Error\")\n",
    "par.set_ylabel(\"negVLB\")\n",
    "p0, = host.plot(VLB_time, err, 'bo--', lw=1, markersize=5, fillstyle='none', label=\"error GD\")\n",
    "p1, = host.plot(VLB_time_FPi, err_FPi, 'ro--', lw=1, markersize=5, fillstyle='none', label=\"error FPi\")\n",
    "p2, = host.plot(VLB_time_FPb, err_FPb, 'go--', lw=1, markersize=5, fillstyle='none', label=\"error FPb\")\n",
    "p3, = host.plot(VLB_time_FPim, err_FPim, 'co--', markersize=5, lw=1, fillstyle='none', label=\"error FPi-mean\")\n",
    "p4, = par.plot(VLB_time, VLB, 'bo-', lw=1, markersize=5, label=\"negVLB GD\")\n",
    "p5, = par.plot(VLB_time_FPi, VLB_FPi, 'ro-', lw=1, markersize=5, label=\"negVLB FPi\")\n",
    "p6, = par.plot(VLB_time_FPb, VLB_FPb, 'go-', lw=1, markersize=5, label=\"negVLB FPb\")\n",
    "p7, = par.plot(VLB_time_FPim, VLB_FPim, 'c+-', lw=1, markersize=5, label=\"negVLB FPi-mean\")\n",
    "host.set_xscale('log',basex=10)\n",
    "leg = plt.legend()\n",
    "host.yaxis.get_label().set_color(p0.get_color());par.yaxis.get_label().set_color(p0.get_color())\n",
    "leg.texts[0].set_color(p0.get_color());\n",
    "leg.texts[1].set_color(p1.get_color())\n",
    "leg.texts[2].set_color(p2.get_color());\n",
    "leg.texts[3].set_color(p3.get_color())\n",
    "leg.texts[4].set_color(p4.get_color());\n",
    "leg.texts[5].set_color(p5.get_color())\n",
    "leg.texts[6].set_color(p6.get_color());\n",
    "leg.texts[7].set_color(p7.get_color())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some 1D training data(regression)\n",
    "num_train = 2000;num_test=700                         # 500 training poitns\n",
    "X_train = np.linspace(0, 10, num_train)[:,None]       # Inputs evenly spaced between 0 and 10\n",
    "F = np.sin(X_train)                   # True function (f = sin(x))\n",
    "y_train = F + 0.01*np.random.randn(num_train)[:,None]  # Observations\n",
    "X_test = np.linspace(0, 10, num_test)[:,None]       # Inputs evenly spaced between 0 and 10\n",
    "F_test = np.sin(X_test)                   # True function (f = sin(x))\n",
    "y_test = F_test + 0.01*np.random.randn(num_test)[:,None]  # Observations\n",
    "np.random.seed(4);num_inducing=200\n",
    "ix = random.sample(range(num_train), num_inducing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data from file, make sure banana.csv is in the same directory as this notebook\n",
    "data = np.genfromtxt('banana.csv', delimiter=',')\n",
    "\n",
    "# Dimension of data\n",
    "D = data.shape[1]-1\n",
    "\n",
    "# Seperate our data (input) from its corresponding label output\n",
    "# .. note we have to rescale from [-1,1] to [0,1] for a Bernoulli distribution\n",
    "X, y = data[:,:D], data[:,-1][:, None]\n",
    "\n",
    "# We will plot our data as well\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# Plot 0 class in blue\n",
    "plt.plot(X[np.where(y == -1),0],X[np.where(y == -1),1],'bo', mew=0.5, alpha=0.5)\n",
    "# Plot 1 class in red\n",
    "plt.plot(X[np.where(y == 1),0],X[np.where(y == 1),1],'ro', mew=0.5, alpha=0.5)\n",
    "\n",
    "# Annotate plot\n",
    "plt.xlabel(\"$x_1$\"), plt.ylabel(\"$x_2$\")\n",
    "plt.title(\"Banana Dataset (red=1, blue=0)\")\n",
    "plt.axis(\"square\"), plt.xlim((-3, 3)), plt.ylim((-3, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from file, make sure banana.csv is in the same directory as this notebook\n",
    "data = np.genfromtxt('banana.csv', delimiter=',')\n",
    "\n",
    "# Dimension of data\n",
    "D = data.shape[1]-1\n",
    "n = data.shape[0]\n",
    "# Seperate our data (input) from its corresponding label output\n",
    "# .. note we have to rescale from [-1,1] to [0,1] for a Bernoulli distribution\n",
    "X, y = data[:,:D], data[:,-1][:, None]\n",
    "num_train = 3000; num_test = n - num_train\n",
    "X_train, y_train = X[:num_train,:], y[:num_train]\n",
    "X_test, y_test = X[:num_test,:], y[:num_test]\n",
    "np.random.seed(3);num_inducing=100 # randomly select active set and then keep them fixed\n",
    "ix = random.sample(range(num_train), num_inducing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "num = np.arange(-39,40);print(num)\n",
    "plt.figure(1)\n",
    "a1 = norm.cdf(num);print(a1)\n",
    "a2 = norm.pdf(num);print(a2)\n",
    "plt.plot(a1)\n",
    "plt.plot(a2)\n",
    "plt.figure(2)\n",
    "r = norm.pdf(num)/norm.cdf(num)\n",
    "plt.plot(r);print(r.shape)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014664552275896692"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(4.703)-norm.cdf(2.179)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.linalg.eigvals(V) > 0)# check PSD condition for V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "  'a': lambda x: x * 5,\n",
    "  'b': lambda x: x + 7,\n",
    "  'c': lambda x: x - 2\n",
    "}[value](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "X_train, y_train = load_svmlight_file(\"segment.txt\")#segment,cpusmall,mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2310, 19)\n",
      "(2310, 1)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "X_train=scipy.sparse.csr_matrix.todense(X_train)\n",
    "y_train=y_train[:,None]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat('count_dataset_segment_N2319_D19.mat',{'x':X_train,'y':y_train})#count_dataset_segment_N2319_D19,reg_dataset_cpusmall_N8192_D12,reg_dataset_mg_N1385_D6,reg_dataset_spacega_N3107_D6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "fruitfly_data = fetch_openml(name='fruitfly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 4)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruitfly_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125,)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruitfly_data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.717797887081348"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2*np.sqrt(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04999871830948721"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(20.5/np.sqrt(19))-0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-373.3302492632022"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.ppf(0.95)*np.sqrt(19)-380.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999546000702375"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.exp(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.802381130396078"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(365*0.022*(1-0.022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05903786925436102"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "norm.cdf((55.5*8-365)/np.sqrt(365*7))-norm.cdf((39.5*8-365)/np.sqrt(365*7))\n",
    "1-norm.cdf((55.5*8-365)/np.sqrt(365*7))+norm.cdf((-4-365)/np.sqrt(365*7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7747879755670779"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf((55.5*8-365)/np.sqrt(365*7))-norm.cdf((39.5*8-365)/np.sqrt(365*7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16617415517856102"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf((39.5*8-365)/np.sqrt(365*7))-norm.cdf((-4-365)/np.sqrt(365*7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16635116057277782\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "a=0\n",
    "for i in range(40):\n",
    "#     print(i)\n",
    "    a+=comb(365,i)*(1/8)**i*(7/8)**(365-i)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0384521484375"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.factorial(7)/(4*8**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 9 6 4 0 6 5]\n",
      " [0 2 6 1 7 1 1]\n",
      " [3 7 2 9 6 5 7]\n",
      " [6 2 9 4 3 5 4]\n",
      " [6 5 6 0 5 6 0]\n",
      " [5 3 0 1 2 3 7]\n",
      " [0 3 4 8 5 7 5]]\n",
      "[[0.  4.5 4.5 5.  3.  5.5 2.5]\n",
      " [4.5 2.  6.5 1.5 6.  2.  2. ]\n",
      " [4.5 6.5 2.  9.  6.  2.5 5.5]\n",
      " [5.  1.5 9.  4.  1.5 3.  6. ]\n",
      " [3.  6.  6.  1.5 5.  4.  2.5]\n",
      " [5.5 2.  2.5 3.  4.  3.  7. ]\n",
      " [2.5 2.  5.5 6.  2.5 7.  5. ]]\n",
      "[2, 1, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.5, 4.5, 3. ],\n",
       "       [6.5, 2. , 6. ],\n",
       "       [2. , 6.5, 6. ],\n",
       "       [9. , 1.5, 1.5],\n",
       "       [6. , 6. , 5. ],\n",
       "       [2.5, 2. , 4. ],\n",
       "       [5.5, 2. , 2.5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=np.random.randint(10, size=(7, 7));print(aa)\n",
    "aa=(aa+aa.T)/2;print(aa)\n",
    "indx = random.sample(range(7), 3);print(indx)\n",
    "rows=np.arange(len(aa))\n",
    "cols=np.asarray(indx, dtype=np.intp)\n",
    "aa[np.ix_(rows, cols)]\n",
    "# aa[np.arange(len(aa)), cols]\n",
    "# rows=cols=np.asarray(indx, dtype=np.intp);\n",
    "\n",
    "# aa[np.ix_(rows, cols)]\n",
    "# rows=np.array([[3,3,3],\n",
    "#              [2,2,2],\n",
    "#              [5,5,5]]);print(rows)\n",
    "# cols=np.array([[3,2,5],\n",
    "#              [3,2,5],\n",
    "#              [3,2,5]]);print(cols)\n",
    "# Z = aa[rows, cols];print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 1190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4385731106295192"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-2)*(5)-np.exp(-4)*(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
